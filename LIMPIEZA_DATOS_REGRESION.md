# üßπ Limpieza de Datos para REGRESI√ìN vs CLASIFICACI√ìN

## ¬øPor qu√© es DIFERENTE?

### TL;DR
- **Clasificaci√≥n**: Puede tolerar NaN (rellenar con median/0)
- **Regresi√≥n**: Muy sensible a NaN (causa problemas en MSE/MAE)

---

## üìä Comparaci√≥n de Estrategias

| Aspecto | Clasificaci√≥n | Regresi√≥n |
|---------|---------------|-----------|
| **NaN Handling** | Forward fill + Median | Interpolaci√≥n temporal + Remoci√≥n agresiva |
| **Outliers** | Menos cr√≠tico | CR√çTICO (detectar valores imposibles) |
| **Missing Data** | Tolera hasta 10% | Tolera hasta 5% |
| **Interpolaci√≥n** | Simple (ffill/bfill) | Temporal (time-aware linear) |
| **Validaci√≥n** | Chequeo b√°sico | Exhaustiva (unique values, range, distribution) |

---

## üîç Diferencias T√©cnicas

### 1Ô∏è‚É£ **Manejo de NaN**

#### CLASIFICACI√ìN (`clean_classification_data.py`)
```python
# Estrategia: Forward fill + Median (simple)
df[feature_cols] = df[feature_cols].fillna(method='ffill')
df[feature_cols] = df[feature_cols].fillna(df[feature_cols].median())
```

**Problema para regresi√≥n**: Median global puede distorsionar patrones temporales

#### REGRESI√ìN (`clean_regression_data.py`)
```python
# Estrategia: Interpolaci√≥n temporal por regi√≥n
for region in df['region'].unique():
    region_df = df[df['region'] == region]
    
    # Interpolaci√≥n lineal (time-aware)
    region_df[feature_cols] = region_df[feature_cols].interpolate(
        method='linear',
        limit_direction='both',
        limit=5  # M√°ximo 5 pasos (2.5 d√≠as)
    )
    
    # Forward/Backward fill (para gaps peque√±os)
    region_df[feature_cols] = region_df[feature_cols].fillna(method='ffill', limit=3)
    region_df[feature_cols] = region_df[feature_cols].fillna(method='bfill', limit=3)

# Remoci√≥n agresiva (si a√∫n quedan NaN)
df = df.dropna(subset=feature_cols)
```

**Por qu√© mejor**: Preserva patrones temporales, respeta estructura regional

---

### 2Ô∏è‚É£ **Detecci√≥n de Outliers**

#### CLASIFICACI√ìN
No tiene detecci√≥n espec√≠fica (binario 0/1 no tiene outliers)

#### REGRESI√ìN
```python
# Remover valores negativos (imposibles)
df = df[df['target_precip_24h'] >= 0]

# Remover valores extremos (> 200mm/d√≠a)
# 200mm = evento El Ni√±o extremo (l√≠mite razonable)
df = df[df['target_precip_24h'] <= 200.0]
```

**Por qu√© cr√≠tico**: Valores imposibles (negativos) o errores de medici√≥n (>500mm) distorsionan MSE

---

### 3Ô∏è‚É£ **Validaci√≥n de Calidad**

#### CLASIFICACI√ìN
```python
# Validaci√≥n b√°sica
assert df['target'].nunique() == 2  # Binary check
assert df['target'].min() == 0
assert df['target'].max() == 1
```

#### REGRESI√ìN
```python
# Validaci√≥n exhaustiva
unique_count = df['target_precip_24h'].nunique()

# CR√çTICO: Detectar si datos son binarios (ERROR)
if unique_count < 100:
    raise ValueError("Data appears to be binary, not continuous!")

# Verificar rango razonable
assert df['target_precip_24h'].min() >= 0, "Negative precipitation!"
assert df['target_precip_24h'].max() < 200, "Extreme outlier!"

# Verificar distribuci√≥n
rainy_pct = (df['target_precip_24h'] > 0.1).sum() / len(df)
assert 0.10 < rainy_pct < 0.40, f"Unusual rainy percentage: {rainy_pct}"
```

**Por qu√© exhaustiva**: Un error en los datos (binario vs continuo) invalida TODO el entrenamiento

---

## üö® Casos Problem√°ticos

### PROBLEMA 1: Usar CSV de Clasificaci√≥n para Regresi√≥n

```python
# ‚ùå MAL: Usar peru_rainfall_cleaned.csv (binario)
df = pd.read_csv('peru_rainfall_cleaned.csv')
print(df['rain_24h'].unique())  # [0, 1]  ‚Üê BINARIO

# Entrenar "regresi√≥n" en datos binarios
# RMSE = 0.45 ‚Üê No tiene sentido comparar con NASA IMERG (3.4mm)
```

**Soluci√≥n**: Usar `peru_rainfall_regression_cleaned.csv` (continuo)

---

### PROBLEMA 2: NaN en Features

```python
# Ejemplo: Temperatura tiene NaN en 3 d√≠as consecutivos

# ‚ùå MAL (Clasificaci√≥n): Rellenar con median
df['temperature'].fillna(df['temperature'].median())
# Problema: 3 d√≠as con EXACTAMENTE el mismo valor (irreal)

# ‚úÖ BIEN (Regresi√≥n): Interpolaci√≥n temporal
df['temperature'].interpolate(method='linear', limit=5)
# Resultado: 20.1 ‚Üí 20.3 ‚Üí 20.5 ‚Üí 20.7 (gradiente natural)
```

---

### PROBLEMA 3: Outliers Extremos

```python
# Caso real: Error en sensor report√≥ 15000 mm (15 metros) de lluvia

# ‚ùå Clasificaci√≥n: No lo detecta (se binariza a 1 de todas formas)

# ‚úÖ Regresi√≥n: Detecta y elimina
if df['target_precip_24h'].max() > 200:
    print(f"Outlier detectado: {df['target_precip_24h'].max()} mm")
    df = df[df['target_precip_24h'] <= 200]
```

---

## üìù Pipeline Completo: REGRESI√ìN

```bash
# PASO 1: Preprocesar desde .nc (METERS ‚Üí MM)
python preprocessing/preprocess_era5_regression.py \
    --input_dir datasets/raw_era5 \
    --output_dir datasets/processed \
    --years 2014,2015,...,2024

# Output: peru_rainfall_regression.csv
# Contenido: valores continuos [0.0, 100.0] mm

# PASO 2: Limpiar datos (NaN, outliers, validaci√≥n)
python preprocessing/clean_regression_data.py \
    --input_path datasets/processed/peru_rainfall_regression.csv \
    --output_path datasets/processed/peru_rainfall_regression_cleaned.csv \
    --max_precip 200.0

# Output: peru_rainfall_regression_cleaned.csv
# Garant√≠as:
#   ‚úÖ Sin NaN en features
#   ‚úÖ Sin outliers extremos
#   ‚úÖ Valores continuos (unique > 100)
#   ‚úÖ Rango v√°lido [0, 200] mm

# PASO 3: Entrenar Timer-XL
python run.py \
    --task_name long_term_forecast \
    --data_path peru_rainfall_regression_cleaned.csv \
    --loss MSE \
    ...
```

---

## üéØ Checklist de Validaci√≥n

Antes de entrenar regresi√≥n, verificar:

```python
import pandas as pd

df = pd.read_csv('datasets/processed/peru_rainfall_regression_cleaned.csv')

# ‚úÖ Check 1: Sin NaN
assert df.isnull().sum().sum() == 0, "Found NaN values!"

# ‚úÖ Check 2: Valores continuos (NO binarios)
unique_count = df['target_precip_24h'].nunique()
assert unique_count > 100, f"Only {unique_count} unique values (binary?)"

# ‚úÖ Check 3: Rango v√°lido
assert df['target_precip_24h'].min() >= 0, "Negative precipitation!"
assert df['target_precip_24h'].max() <= 200, "Extreme outlier!"

# ‚úÖ Check 4: Distribuci√≥n razonable
mean_precip = df['target_precip_24h'].mean()
assert 2.0 < mean_precip < 6.0, f"Unusual mean: {mean_precip}"

rainy_pct = (df['target_precip_24h'] > 0.1).sum() / len(df) * 100
assert 15 < rainy_pct < 35, f"Unusual rainy %: {rainy_pct}"

print("‚úÖ Todos los checks pasados - listo para regresi√≥n")
```

---

## üìä Estad√≠sticas Esperadas

### Clasificaci√≥n (Binary)
```json
{
  "target_column": "rain_24h",
  "unique_values": 2,
  "values": [0, 1],
  "class_0_pct": 71.3,
  "class_1_pct": 28.7
}
```

### Regresi√≥n (Continuous)
```json
{
  "target_column": "target_precip_24h",
  "unique_values": 2847,
  "range": [0.0, 87.3],
  "mean": 3.54,
  "median": 0.82,
  "std": 6.21,
  "rainy_pct": 24.6,
  "heavy_rain_pct": 8.3,
  "extreme_rain_pct": 1.2
}
```

**Diferencia clave**: 
- Clasificaci√≥n: **2 valores √∫nicos** (binario)
- Regresi√≥n: **2847 valores √∫nicos** (continuo)

---

## üí° Recomendaciones Finales

### Para tu Tesis

1. **Documentar diferencias**: Explica en Cap√≠tulo 3 (Metodolog√≠a) por qu√© la limpieza es diferente

2. **Justificar umbral 200mm**: 
   - Citar eventos El Ni√±o hist√≥ricos
   - Mostrar que > 200mm son errores de sensor (no eventos reales)

3. **Validar interpolaci√≥n**:
   - Comparar RMSE con/sin interpolaci√≥n
   - Mostrar que interpolaci√≥n mejora resultados (preserva patrones)

4. **Tabla comparativa**:
   ```markdown
   | Aspecto | Clasificaci√≥n | Regresi√≥n | Justificaci√≥n |
   |---------|---------------|-----------|---------------|
   | NaN handling | Median fill | Temporal interpolation | Preserva patrones |
   | Outliers | No aplica | Detecci√≥n activa | Evita distorsi√≥n MSE |
   | Target | Binary {0,1} | Continuous [0,200]mm | Domain-aligned |
   ```

---

## üîó Referencias

- **ERA5 Data Quality**: ECMWF (2023) - Precipitation validation
- **Interpolation Methods**: Pandas documentation - Time series interpolation
- **Outlier Detection**: IQR method + domain knowledge (200mm threshold)
- **Literature Benchmarks**: 
  - NASA IMERG: RMSE ~3.4 mm (after quality control)
  - ERA5-Land: MAE ~2.5 mm (with outlier removal)

---

## ‚úÖ Resumen Ejecutivo

**CLASIFICACI√ìN**:
- Datos binarios (0/1)
- Limpieza simple (forward fill + median)
- Tolera NaN moderado
- No requiere detecci√≥n de outliers

**REGRESI√ìN**:
- Datos continuos (0-200 mm)
- Limpieza sofisticada (interpolaci√≥n temporal)
- Muy sensible a NaN (remoci√≥n agresiva)
- Requiere validaci√≥n exhaustiva (unique values, range, distribution)
- Detecci√≥n de outliers CR√çTICA

**CR√çTICO**: Nunca usar CSV de clasificaci√≥n para regresi√≥n ‚Üí datos binarios hacen RMSE no comparable con literatura.
