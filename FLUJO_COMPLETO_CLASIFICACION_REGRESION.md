# üîÑ FLUJO COMPLETO: Clasificaci√≥n vs Regresi√≥n

## üìä Comparaci√≥n Visual

```mermaid
flowchart TD
    A[Raw ERA5 .nc files] --> B{Tarea?}
    
    B -->|CLASIFICACI√ìN| C1[preprocess_era5_peru.py]
    B -->|REGRESI√ìN| C2[preprocess_era5_regression.py]
    
    C1 --> D1[peru_rainfall.csv]
    C2 --> D2[peru_rainfall_regression.csv]
    
    D1 --> E1[Limpieza Clasificaci√≥n]
    D2 --> E2[Limpieza Regresi√≥n]
    
    E1 --> F1[peru_rainfall_cleaned.csv]
    E2 --> F2[peru_rainfall_regression_cleaned.csv]
    
    F1 --> G1[Target: rain_24h = {0, 1}]
    F2 --> G2[Target: target_precip_24h = [0, 200] mm]
    
    G1 --> H1[Timer-XL Classifier]
    G2 --> H2[Timer-XL Regressor]
    
    H1 --> I1[M√©tricas: F1, Precision, Recall]
    H2 --> I2[M√©tricas: RMSE, MAE, R¬≤]
```

---

## üîç PASO a PASO

### üìÅ **Input**: Archivos .nc (id√©nticos para ambos)

```
datasets/raw_era5/
‚îú‚îÄ‚îÄ era5_peru_2014.nc
‚îú‚îÄ‚îÄ era5_peru_2015.nc
...
‚îî‚îÄ‚îÄ era5_peru_2024.nc

Variables en .nc:
- tp (total_precipitation) ‚Üí METROS
- t2m, d2m, sp, msl, u10, v10, tcwv, cape
```

---

## üîÄ CLASIFICACI√ìN

### PASO 1: Preprocesamiento
```bash
python preprocessing/preprocess_era5_peru.py \
    --input_dir datasets/raw_era5 \
    --years 2014,...,2024 \
    --threshold 0.0001  # ‚Üê BINARIZACI√ìN
```

**Transformaciones**:
1. Leer .nc files
2. Agregar espacialmente (por regi√≥n)
3. **Convertir METROS ‚Üí MM** (√ó1000)
4. **BINARIZAR**: `rain_24h = 1 if precip > 0.1mm else 0`
5. Features engineering (lags, rolling stats)

**Output**: `peru_rainfall.csv`
```python
{
  'timestamp': '2014-01-01',
  'region': 'costa_norte',
  'total_precipitation': 2.5,  # mm (convertido)
  'temperature_2m': 25.3,
  'rain_24h': 1  # ‚Üê BINARIO {0, 1}
}
```

---

### PASO 2: Limpieza (Clasificaci√≥n)
```bash
# ‚ö†Ô∏è Actualmente NO existe script de limpieza para clasificaci√≥n
# Se asume que preprocess_era5_peru.py ya hace limpieza b√°sica
```

**Estrategia** (si se implementara):
- Forward fill para NaN temporales
- Median fill para NaN persistentes
- Sin detecci√≥n de outliers (binario 0/1)

---

### PASO 3: Entrenamiento
```bash
python run.py \
    --task_name classification \
    --data_path peru_rainfall_cleaned.csv \
    --loss CE \
    --use_focal_loss \
    --n_classes 2
```

**M√©tricas**:
- F1-Score: 83.24%
- Recall Rain: 83%
- Recall No Rain: 71%

---

## üåä REGRESI√ìN

### PASO 1: Preprocesamiento
```bash
python preprocessing/preprocess_era5_regression.py \
    --input_dir datasets/raw_era5 \
    --years 2014,...,2024
    # ‚ö†Ô∏è SIN --threshold (NO binarizaci√≥n)
```

**Transformaciones**:
1. Leer .nc files (id√©ntico a clasificaci√≥n)
2. Agregar espacialmente (id√©ntico)
3. **Convertir METROS ‚Üí MM** (√ó1000) (id√©ntico)
4. **NO BINARIZAR**: Preservar valores continuos
5. Features engineering (id√©ntico)
6. **Target continuo**: `target_precip_24h = precip_mm` (NO umbral)

**Output**: `peru_rainfall_regression.csv`
```python
{
  'timestamp': '2014-01-01',
  'region': 'costa_norte',
  'total_precipitation': 2.5,  # mm (convertido)
  'temperature_2m': 25.3,
  'target_precip_24h': 2.5  # ‚Üê CONTINUO [0.0, 200.0] mm
}
```

---

### PASO 2: Limpieza (Regresi√≥n) ‚ú® NUEVO
```bash
python preprocessing/clean_regression_data.py \
    --input_path peru_rainfall_regression.csv \
    --output_path peru_rainfall_regression_cleaned.csv \
    --max_precip 200.0
```

**Estrategia**:
1. **Interpolaci√≥n temporal** (mejor que median)
   ```python
   df.interpolate(method='linear', limit=5)
   ```

2. **Detecci√≥n de outliers**
   ```python
   df = df[df['target_precip_24h'] >= 0]  # Sin negativos
   df = df[df['target_precip_24h'] <= 200]  # Sin extremos
   ```

3. **Remoci√≥n agresiva de NaN**
   ```python
   df = df.dropna(subset=feature_cols)
   ```

4. **Validaci√≥n exhaustiva**
   ```python
   assert df['target_precip_24h'].nunique() > 100  # NO binario
   ```

**Output**: `peru_rainfall_regression_cleaned.csv`
```python
{
  'timestamp': '2014-01-01',
  'region': 'costa_norte',
  'total_precipitation': 2.5,
  'temperature_2m': 25.3,
  'target_precip_24h': 2.5,
  # ‚úÖ SIN NaN
  # ‚úÖ SIN outliers
  # ‚úÖ Valores continuos
}
```

---

### PASO 3: Entrenamiento
```bash
python run.py \
    --task_name long_term_forecast \
    --data_path peru_rainfall_regression_cleaned.csv \
    --loss MSE \
    --pred_len 24
```

**M√©tricas** (esperadas):
- RMSE: 2.5-3.5 mm (vs NASA IMERG: 3.4 mm)
- MAE: 1.8-2.5 mm
- R¬≤: 0.55-0.70

---

## üìä Comparaci√≥n de Archivos

| Archivo | Tarea | Target | Valores √önicos | Limpieza |
|---------|-------|--------|----------------|----------|
| `peru_rainfall.csv` | Clasificaci√≥n | `rain_24h` | 2 | B√°sica (en preproceso) |
| `peru_rainfall_cleaned.csv` | Clasificaci√≥n | `rain_24h` | 2 | N/A (no hay script) |
| `peru_rainfall_regression.csv` | Regresi√≥n | `target_precip_24h` | ~3000 | Pendiente |
| `peru_rainfall_regression_cleaned.csv` | Regresi√≥n | `target_precip_24h` | ~2800 | ‚úÖ Completa |

---

## üö® ERRORES COMUNES

### ‚ùå ERROR 1: Usar CSV equivocado
```python
# MAL: Regresi√≥n con CSV de clasificaci√≥n
python run.py --task_name long_term_forecast \
    --data_path peru_rainfall_cleaned.csv  # ‚Üê BINARIO {0,1}

# Resultado: RMSE = 0.45 (sin sentido)
```

‚úÖ **Correcto**:
```python
python run.py --task_name long_term_forecast \
    --data_path peru_rainfall_regression_cleaned.csv  # ‚Üê CONTINUO [0,200]mm
```

---

### ‚ùå ERROR 2: Olvidar limpieza
```python
# MAL: Entrenar con CSV RAW (tiene NaN)
python run.py --task_name long_term_forecast \
    --data_path peru_rainfall_regression.csv  # ‚Üê Tiene NaN, outliers

# Error: "RuntimeError: Input contains NaN"
```

‚úÖ **Correcto**:
```python
# Primero limpiar
python preprocessing/clean_regression_data.py ...

# Luego entrenar
python run.py --task_name long_term_forecast \
    --data_path peru_rainfall_regression_cleaned.csv
```

---

### ‚ùå ERROR 3: No validar datos
```python
# MAL: Asumir que est√° correcto
df = pd.read_csv('peru_rainfall_regression_cleaned.csv')
# Entrenar sin verificar

# Problema oculto: Datos binarios en "regresi√≥n"
```

‚úÖ **Correcto**:
```python
df = pd.read_csv('peru_rainfall_regression_cleaned.csv')

# Validar SIEMPRE
assert df['target_precip_24h'].nunique() > 100, "Datos binarios!"
assert df.isnull().sum().sum() == 0, "Tiene NaN!"
assert df['target_precip_24h'].max() <= 200, "Outliers extremos!"

print("‚úÖ Validaci√≥n pasada - listo para entrenar")
```

---

## üìù Checklist Completo

### CLASIFICACI√ìN
- [ ] Archivos .nc en `datasets/raw_era5/`
- [ ] Ejecutar `preprocess_era5_peru.py` con `--threshold 0.0001`
- [ ] Verificar `peru_rainfall.csv` tiene columna `rain_24h` con {0, 1}
- [ ] (Opcional) Crear script de limpieza si hay NaN
- [ ] Entrenar con `--task_name classification`
- [ ] Evaluar F1-Score, Precision, Recall

### REGRESI√ìN ‚ú®
- [ ] Archivos .nc en `datasets/raw_era5/` (mismos que clasificaci√≥n)
- [ ] Ejecutar `preprocess_era5_regression.py` SIN `--threshold`
- [ ] Verificar `peru_rainfall_regression.csv` tiene `target_precip_24h` continuo
- [ ] ‚úÖ **Ejecutar `clean_regression_data.py`** (NUEVO, CR√çTICO)
- [ ] Verificar `peru_rainfall_regression_cleaned.csv`:
  - [ ] Sin NaN (`df.isnull().sum().sum() == 0`)
  - [ ] Valores continuos (`df['target_precip_24h'].nunique() > 100`)
  - [ ] Rango v√°lido (`0 <= target <= 200`)
  - [ ] Distribuci√≥n razonable (`mean ‚âà 3-5 mm`)
- [ ] Entrenar con `--task_name long_term_forecast`
- [ ] Evaluar RMSE, MAE, R¬≤

---

## üéØ Archivos Creados (NUEVOS)

1. **`preprocessing/clean_regression_data.py`** ‚ú®
   - Limpieza espec√≠fica para regresi√≥n
   - Interpolaci√≥n temporal (time-aware)
   - Detecci√≥n de outliers
   - Validaci√≥n exhaustiva

2. **`LIMPIEZA_DATOS_REGRESION.md`** ‚ú®
   - Explica diferencias clasificaci√≥n vs regresi√≥n
   - Justifica estrategias de limpieza
   - Ejemplos de validaci√≥n

3. **`FLUJO_COMPLETO_CLASIFICACION_REGRESION.md`** (este archivo) ‚ú®
   - Comparaci√≥n visual completa
   - Checklist paso a paso
   - Errores comunes y soluciones

---

## üìû Contacto R√°pido

**Duda**: ¬øCu√°l CSV usar para regresi√≥n?
**Respuesta**: `peru_rainfall_regression_cleaned.csv`

**Duda**: ¬øPor qu√© crear CSV diferente? ¬øNo puedo usar el de clasificaci√≥n?
**Respuesta**: NO. Clasificaci√≥n tiene target binario {0,1}, regresi√≥n necesita continuo [0,200]mm

**Duda**: ¬øEs necesario limpiar datos de regresi√≥n?
**Respuesta**: S√ç. Regresi√≥n es MUY sensible a NaN y outliers (MSE se dispara). Clasificaci√≥n puede tolerar m√°s.

**Duda**: ¬øQu√© validar antes de entrenar regresi√≥n?
**Respuesta**: 
```python
df['target_precip_24h'].nunique() > 100  # Continuo, NO binario
df.isnull().sum().sum() == 0  # Sin NaN
df['target_precip_24h'].max() <= 200  # Sin outliers
```

---

## ‚úÖ Resumen Ejecutivo

**CLASIFICACI√ìN**:
- Preproceso ‚Üí Binarizaci√≥n ‚Üí Entrenamiento
- Target: `rain_24h = {0, 1}`
- Limpieza: B√°sica (en preproceso)

**REGRESI√ìN**: ‚ú®
- Preproceso ‚Üí **Limpieza (NUEVO)** ‚Üí Entrenamiento
- Target: `target_precip_24h = [0, 200] mm`
- Limpieza: Sofisticada (interpolaci√≥n, outliers, validaci√≥n)

**CR√çTICO**: 
- ‚ùå NO mezclar CSVs (clasificaci√≥n ‚â† regresi√≥n)
- ‚úÖ SIEMPRE limpiar datos de regresi√≥n antes de entrenar
- ‚úÖ VALIDAR datos continuos (unique > 100)
