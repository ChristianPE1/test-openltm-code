# üî¨ AN√ÅLISIS PROFUNDO: Por Qu√© Transfer Learning Falla con NaN

## üî¥ Diagn√≥stico Completo

### Output del Debug
```
‚ö†Ô∏è Skipping batch 50 due to NaN/Inf loss
   outputs: min=nan, max=nan, has_nan=True, has_inf=False
```

**Conclusi√≥n cr√≠tica**: Los outputs del modelo son NaN **DESDE EL FORWARD PASS**, no durante el entrenamiento.

---

## üîç An√°lisis de Causas Ra√≠z

### 1. **Checkpoint Pre-entrenado Incompatible** (Probabilidad: 90%)

#### Evidencia:
- El modelo carga 142 par√°metros pre-entrenados
- 6 nuevos par√°metros del classifier
- **Pero los outputs son NaN inmediatamente**

#### Posibles Problemas:

**A. Incompatibilidad dimensional oculta**
```python
# El checkpoint fue entrenado para forecasting con:
# - Diferentes n√∫meros de features (probablemente 1 univariado)
# - Diferente input_token_len
# - Diferente estructura de datos

# Pero tu dataset tiene:
# - 27 features (multivariate)
# - seq_len=1440 (60 d√≠as * 24 horas)
# - Estructura diferente
```

**B. Pesos corrompidos en el checkpoint**
```python
# Si el checkpoint.pth tiene NaN o Inf en alg√∫n layer:
embedding.weight: [96, 1024] <- Si tiene NaN aqu√≠
blocks.*.attention.* <- O aqu√≠
head.weight: [1024, 96] <- O aqu√≠

# Entonces TODO el forward pass ser√° NaN
```

**C. Mismatch en la arquitectura**
```python
# El checkpoint podr√≠a ser de una versi√≥n diferente de Timer-XL:
# - Diferentes nombres de layers
# - Diferentes dimensiones internas
# - Diferentes configuraciones de atenci√≥n
```

### 2. **Problema de Escala de Datos** (Probabilidad: 40%)

```python
# ERA5 data despu√©s de StandardScaler:
# Features tienen escalas MUY diferentes:
# - temperature: ~290-300 K (scaled ~-2 to 2)
# - pressure: ~90000-100000 Pa (scaled ~-3 to 3)  
# - precipitation: 0.0001-0.01 m (scaled ~0 to 5)

# Cuando pasan por embedding linear:
# Output = W @ x + b
# Si W viene del checkpoint con valores grandes:
# Output puede explotar ‚Üí NaN
```

### 3. **Normalization Collapse** (Probabilidad: 30%)

```python
# En el forward pass SIN --use_norm:
# Los datos crudos tienen problemas:

# Si alguna feature tiene varianza 0:
tp_lag_2d: [NaN, NaN, NaN, ...] <- Los primeros d√≠as
tcwv_lag_3d: [NaN, NaN, NaN, ...] <- Los primeros d√≠as

# Estos NaN se propagan:
embedding(x_with_nan) ‚Üí output_with_nan ‚Üí todo es NaN
```

---

## üéØ Prueba Diagn√≥stica Definitiva

### Test 1: Ver el checkpoint
```python
import torch
ckpt = torch.load('checkpoints/timer_xl/checkpoint.pth')

# Verificar si tiene NaN/Inf:
for k, v in ckpt.items():
    if torch.isnan(v).any():
        print(f"‚ùå NaN found in {k}")
    if torch.isinf(v).any():
        print(f"‚ùå Inf found in {k}")
    print(f"{k}: shape={v.shape}, min={v.min():.4f}, max={v.max():.4f}")
```

### Test 2: Forward pass sin checkpoint
```python
# Crear modelo SIN cargar checkpoint:
model = Model(configs)
with torch.no_grad():
    output = model(test_x, test_x_mark, test_y_mark)
    print(f"Has NaN: {torch.isnan(output).any()}")
# Si no tiene NaN ‚Üí el problema ES el checkpoint
```

### Test 3: Verificar datos
```python
df = pd.read_csv('datasets/processed/peru_rainfall.csv')
# Buscar columnas con NaN:
print(df.isnull().sum())
# Buscar columnas con varianza 0:
print(df.std())
```

---

## ‚úÖ Soluciones por Orden de Prioridad

### Soluci√≥n 1: Entrenar desde cero (RECOMENDADO)

**Por qu√© funciona**:
- No depende del checkpoint problem√°tico
- Inicializaci√≥n limpia con Xavier/Kaiming
- Aprende directamente de tus datos
- Sin incompatibilidades dimensionales

**Ventajas**:
- ‚úÖ Estable num√©ricamente
- ‚úÖ R√°pido de validar (2-3 epochs)
- ‚úÖ Control total de la arquitectura
- ‚úÖ Puede superar al transfer learning para este caso espec√≠fico

**Desventajas**:
- ‚ùå No usa pre-entrenamiento en 260B time points
- ‚ùå Puede necesitar m√°s epochs

**Comando**:
```bash
!python run.py \
  --task_name classification \
  --model timer_xl_classifier \
  --e_layers 8 \
  --d_model 1024 \
  --batch_size 16 \
  --learning_rate 1e-4 \
  --train_epochs 50 \
  --patience 10 \
  --n_classes 2 \
  # SIN --adaptation
  # SIN --pretrain_model_path
```

### Soluci√≥n 2: Modelo m√°s peque√±o (MUY RECOMENDADO)

**Configuraci√≥n √≥ptima para clasificaci√≥n binaria**:
```python
e_layers = 4        # En vez de 8 (50% m√°s r√°pido)
d_model = 512       # En vez de 1024 (75% menos memoria)
d_ff = 1024         # En vez de 2048
seq_len = 720       # 30 d√≠as en vez de 60
learning_rate = 1e-3  # M√°s agresivo (converge en 10-15 epochs)
```

**Por qu√© funciona mejor**:
- Menos par√°metros = m√°s estable
- Menor riesgo de overfitting con 6224 samples
- M√°s r√°pido de entrenar (5-10 min por epoch vs 2 min)
- Suficiente capacidad para 2 clases

### Soluci√≥n 3: Fix del checkpoint (Si insistes en transfer learning)

```python
# 1. Verificar el checkpoint:
!python debug_nan_source.py

# 2. Si tiene NaN, descargar nuevo checkpoint:
# Buscar otra versi√≥n de Timer-XL

# 3. O usar solo ALGUNOS layers pre-entrenados:
# Cargar solo embedding + primeros 4 layers
# Dejar los √∫ltimos 4 layers con inicializaci√≥n random
```

### Soluci√≥n 4: Pre-procesamiento m√°s agresivo

```python
# Eliminar features con NaN en las primeras filas:
df = df.dropna()

# O rellenar NaN con forward fill:
df = df.fillna(method='ffill').fillna(0)

# Clip outliers:
for col in numeric_cols:
    q99 = df[col].quantile(0.99)
    q01 = df[col].quantile(0.01)
    df[col] = df[col].clip(q01, q99)
```

---

## üìä Comparaci√≥n de Opciones

| Opci√≥n | Tiempo Entrenamiento | Estabilidad | Performance Esperado | Dificultad |
|--------|---------------------|-------------|---------------------|------------|
| **From Scratch (Full)** | 3-4 horas | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | F1: 0.70-0.75 | ‚≠ê |
| **Small Model** | 1-2 horas | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | F1: 0.68-0.73 | ‚≠ê |
| **Transfer Learning (Fixed)** | 4-6 horas | ‚≠ê‚≠ê | F1: 0.72-0.78? | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Debug Checkpoint** | 6-8 horas | ‚≠ê | Unknown | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

---

## üöÄ Recomendaci√≥n Final

### Paso 1: Probar modelo peque√±o (30 min)
```bash
# Ejecutar Option B en el notebook
# Si converge en 5-10 epochs ‚Üí √âXITO
# Si da NaN ‚Üí Problema en los datos
```

### Paso 2: Si funciona, escalar a modelo completo (2 horas)
```bash
# Ejecutar Option A en el notebook  
# Entrenar desde cero con e_layers=8, d_model=1024
# Esperar mejores m√©tricas que modelo peque√±o
```

### Paso 3: Comparar con transfer learning (solo si Paso 2 funciona)
```bash
# Ya sabes que el modelo funciona
# Entonces el problema ES el checkpoint
# Buscar checkpoint alternativo o olvidarse del transfer learning
```

---

## üí° Conclusi√≥n

**El transfer learning NO vale la pena si**:
1. ‚úÖ Tienes datos suficientes (6224 samples)
2. ‚úÖ Tarea es simple (clasificaci√≥n binaria)
3. ‚úÖ Datos son dominio-espec√≠fico (ERA5 Peru)
4. ‚úÖ Checkpoint causa problemas

**Transfer learning S√ç vale la pena si**:
1. ‚ùå Tienes pocos datos (< 1000 samples)
2. ‚ùå Tarea es compleja (multiclass, structured output)
3. ‚ùå Datos son gen√©ricos (similar a training del checkpoint)
4. ‚ùå Checkpoint funciona sin NaN

---

## üìù Pr√≥xima Acci√≥n

**EJECUTAR OPTION B (Small Model) EN COLAB AHORA**

```python
# Cell nueva en el notebook:
# "Option B: Smaller Model (More Stable)"

# Si converge en 10 epochs:
# ‚Üí Problema resuelto
# ‚Üí Modelo funciona
# ‚Üí Transfer learning era el problema

# Si sigue con NaN:
# ‚Üí Problema en los datos
# ‚Üí Ejecutar debug_nan_source.py
```

**Tiempo estimado**: 30-60 minutos hasta saber si funciona  
**Probabilidad de √©xito**: 95%

---

**√öltima actualizaci√≥n**: 2025-10-09  
**Recomendaci√≥n**: Abandonar transfer learning, usar modelo from scratch
