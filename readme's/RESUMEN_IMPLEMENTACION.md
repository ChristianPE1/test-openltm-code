# ðŸŽ¯ AdaptationOpenLTM - Resumen de ImplementaciÃ³n

## âœ… Cambios Implementados

### ðŸ“ Estructura de Carpetas Creada

```
AdaptationOpenLTM/
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ raw_era5/          â† SUBIR ARCHIVOS .zip AQUÃ
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ processed/         â† Datos procesados (generado automÃ¡ticamente)
â”‚
â”œâ”€â”€ preprocessing/
â”‚   â””â”€â”€ preprocess_era5_peru.py  â† Script de preprocesamiento
â”‚
â”œâ”€â”€ data_provider/
â”‚   â”œâ”€â”€ data_loader_peru.py      â† DataLoader para clasificaciÃ³n binaria
â”‚   â””â”€â”€ data_factory.py           â† Actualizado con PeruRainfall
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ timer_xl_classifier.py   â† Timer-XL adaptado para clasificaciÃ³n
â”‚
â”œâ”€â”€ exp/
â”‚   â”œâ”€â”€ exp_basic.py              â† Actualizado con timer_xl_classifier
â”‚   â””â”€â”€ exp_forecast.py           â† Modificado para soportar clasificaciÃ³n
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ tools.py                  â† Agregado FocalLoss
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ adaptation/
â”‚       â””â”€â”€ peru_rainfall/
â”‚           â””â”€â”€ train_timerxl_peru.sh  â† Script de entrenamiento
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ colab_training_demo.ipynb     â† Demo para Google Colab
â”‚
â”œâ”€â”€ results/                           â† Resultados (generado automÃ¡ticamente)
â”‚
â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ timer_xl/
â”‚       â””â”€â”€ checkpoint.pth            â† Modelo pre-entrenado (descargar)
â”‚
â”œâ”€â”€ README_PERU_RAINFALL.md           â† README principal del proyecto
â”œâ”€â”€ GUIA_DESCARGA_DATOS.md            â† GuÃ­a de descarga de ERA5
â””â”€â”€ CAMBIOS_RUN_PY.md                 â† Cambios necesarios en run.py
```

---

## ðŸš€ Pasos para Ejecutar (Quick Start)

### **Paso 1: Preparar Repositorio**

```bash
# 1. Subir la carpeta AdaptationOpenLTM a GitHub
cd AdaptationOpenLTM
git init
git add .
git commit -m "Initial commit: Timer-XL adaptation for Peru rainfall"
git remote add origin https://github.com/TU_USUARIO/AdaptationOpenLTM.git
git push -u origin main
```

### **Paso 2: Descargar Checkpoint Pre-entrenado**

```bash
# Descargar de: https://cloud.tsinghua.edu.cn/f/01c35ca13f474176be7b/
# Guardar en: checkpoints/timer_xl/checkpoint.pth
```

### **Paso 3: Subir Datos ERA5**

**OpciÃ³n A: Descargar primero (Recomendado)**
- Ir a CDS Copernicus: https://cds.climate.copernicus.eu/
- Descargar aÃ±os 2022, 2023, 2024 (ver `GUIA_DESCARGA_DATOS.md`)
- Guardar como: `era5_peru_2022.zip`, `era5_peru_2023.zip`, `era5_peru_2024.zip`
- Subir a `datasets/raw_era5/` en tu repositorio o Google Drive

**OpciÃ³n B: Usar datos existentes**
- Si ya tienes `cds_2023.zip` y `cds_2024.zip`
- Renombrar a `era5_peru_2023.zip` y `era5_peru_2024.zip`
- Subir a `datasets/raw_era5/`

### **Paso 4: Modificar run.py**

Seguir instrucciones en `CAMBIOS_RUN_PY.md` para agregar:
- `--n_classes`
- `--use_focal_loss`
- `--class_weights`

### **Paso 5: Ejecutar en Google Colab**

```python
# En Google Colab
!git clone https://github.com/TU_USUARIO/AdaptationOpenLTM.git
%cd AdaptationOpenLTM

# Instalar dependencias
!pip install -r requirements.txt

# Subir datos ERA5 (o copiar desde Drive)
from google.colab import drive
drive.mount('/content/drive')
!cp /content/drive/MyDrive/ERA5_Data/*.zip datasets/raw_era5/

# Preprocesar
!python preprocessing/preprocess_era5_peru.py \
    --input_dir datasets/raw_era5 \
    --output_dir datasets/processed \
    --years 2023,2024 \
    --target_horizon 24

# Entrenar
!bash scripts/adaptation/peru_rainfall/train_timerxl_peru.sh
```

O usar el notebook: `notebooks/colab_training_demo.ipynb`

---

## ðŸ“Š ConfiguraciÃ³n Recomendada

### **Para Pruebas Iniciales (3 aÃ±os)**

```bash
# Datos
aÃ±os = [2022, 2023, 2024]

# Modelo
seq_len = 1440        # 720 dÃ­as de contexto
batch_size = 256      # Ajustar segÃºn GPU
learning_rate = 1e-5
epochs = 50

# Tiempo esperado en T4
preprocesamiento: ~15 min
entrenamiento: ~3-4 horas
```

### **Para Modelo Final (10 aÃ±os)**

```bash
# Datos
aÃ±os = [2014-2024]

# Modelo
seq_len = 2880        # 1440 dÃ­as (2 aÃ±os) de contexto
batch_size = 128      # Reducido por mÃ¡s contexto
learning_rate = 1e-5
epochs = 50

# Tiempo esperado en T4
preprocesamiento: ~1.5 horas
entrenamiento: ~12-15 horas
```

---

## ðŸŽ¯ Experimentos de AblaciÃ³n (Context Length)

Una vez validado el pipeline con 3 aÃ±os, ejecutar:

```bash
# Experimento 1: 90 dÃ­as de contexto
seq_len=180  # 90 dÃ­as * 2 (12h)
python run.py --seq_len 180 --model_id "context_90d" ...

# Experimento 2: 180 dÃ­as
seq_len=360
python run.py --seq_len 360 --model_id "context_180d" ...

# Experimento 3: 1 aÃ±o
seq_len=730
python run.py --seq_len 730 --model_id "context_1y" ...

# Experimento 4: 2 aÃ±os
seq_len=1460
python run.py --seq_len 1460 --model_id "context_2y" ...

# Experimento 5: 3 aÃ±os
seq_len=2190
python run.py --seq_len 2190 --model_id "context_3y" ...
```

---

## ðŸ“ˆ MÃ©tricas Esperadas

### **Con 3 aÃ±os de datos**
```
F1-Score: 0.65-0.72
AUC-ROC: 0.75-0.82
Recall: 0.60-0.70
```

### **Con 10 aÃ±os de datos**
```
F1-Score: 0.75-0.82
AUC-ROC: 0.85-0.92
Recall: 0.72-0.82
```

### **Objetivo de Tesis (MÃ­nimo Aceptable)**
```
F1-Score: > 0.70
AUC-ROC: > 0.80
Recall: > 0.65
```

---

## ðŸ”§ Troubleshooting ComÃºn

### **Error: Import "torch" could not be resolved**
- Esto es solo un warning de VSCode
- No afecta la ejecuciÃ³n en Colab
- Instalar torch localmente si quieres eliminar el warning: `pip install torch`

### **Error: CUDA Out of Memory**
```bash
# Reducir batch_size
--batch_size 128  # o 64

# Reducir seq_len
--seq_len 720  # en lugar de 1440
```

### **Error: File not found despuÃ©s de extraction**
```bash
# Verificar estructura dentro del .zip
unzip -l datasets/raw_era5/era5_peru_2023.zip

# Si el .nc estÃ¡ en subdirectorio, extraer manualmente
unzip datasets/raw_era5/era5_peru_2023.zip -d datasets/raw_era5/
mv datasets/raw_era5/subdirectory/*.nc datasets/raw_era5/era5_peru_2023.nc
```

### **Error: Variable not found in NetCDF**
- Verificar que el archivo ERA5 contiene las 10 variables necesarias
- Ver `datasets/raw_era5/README.md` para lista de variables
- Re-descargar con las variables correctas si es necesario

---

## ðŸ“š Archivos de DocumentaciÃ³n

1. **README_PERU_RAINFALL.md** - VisiÃ³n general del proyecto
2. **GUIA_DESCARGA_DATOS.md** - GuÃ­a detallada de descarga ERA5
3. **CAMBIOS_RUN_PY.md** - Modificaciones necesarias en run.py
4. **datasets/raw_era5/README.md** - Instrucciones para subir datos
5. **ESTE ARCHIVO (RESUMEN_IMPLEMENTACION.md)** - Resumen ejecutivo

---

## ðŸŽ“ RecomendaciÃ³n Final

### **Semana 1-2: ValidaciÃ³n**
1. âœ… Descargar 3 aÃ±os (2022-2024)
2. âœ… Ejecutar pipeline completo
3. âœ… Obtener mÃ©tricas preliminares
4. âœ… Ajustar hiperparÃ¡metros si es necesario

### **Semana 3-4: Modelo Final**
1. âœ… Si resultados son prometedores, descargar 10 aÃ±os
2. âœ… Entrenar modelo final
3. âœ… Ejecutar experimentos de ablaciÃ³n
4. âœ… Analizar por fase ENSO

### **Semana 5+: AnÃ¡lisis**
1. âœ… Generar figuras para tesis
2. âœ… AnÃ¡lisis de errores
3. âœ… ComparaciÃ³n por regiones
4. âœ… Escribir resultados

---

## ðŸ“ž PrÃ³ximos Pasos Inmediatos

1. **Subir AdaptationOpenLTM a GitHub**
   ```bash
   git init
   git add .
   git commit -m "Timer-XL adaptation for Peru rainfall"
   git remote add origin https://github.com/TU_USUARIO/AdaptationOpenLTM.git
   git push -u origin main
   ```

2. **Descargar checkpoint pre-entrenado**
   - URL: https://cloud.tsinghua.edu.cn/f/01c35ca13f474176be7b/
   - Guardar en: `checkpoints/timer_xl/checkpoint.pth`

3. **Decidir cantidad de aÃ±os**
   - OpciÃ³n A: 3 aÃ±os (2022-2024) para pruebas rÃ¡pidas
   - OpciÃ³n B: 10 aÃ±os (2014-2024) directamente (mÃ¡s tiempo)
   - **RecomendaciÃ³n**: Empezar con 3 aÃ±os

4. **Descargar ERA5**
   - Seguir `GUIA_DESCARGA_DATOS.md`
   - Subir a `datasets/raw_era5/`

5. **Modificar run.py**
   - Seguir `CAMBIOS_RUN_PY.md`
   - Agregar argumentos de clasificaciÃ³n

6. **Ejecutar en Colab**
   - Usar `notebooks/colab_training_demo.ipynb`
   - O seguir pasos en `README_PERU_RAINFALL.md`

---

## âœ¨ Todo Listo!

Tu repositorio estÃ¡ completamente preparado para:
- âœ… Preprocesamiento de ERA5
- âœ… Transfer learning con Timer-XL
- âœ… ClasificaciÃ³n binaria de lluvias
- âœ… Experimentos de contexto largo
- âœ… AnÃ¡lisis por fase ENSO
- âœ… EjecuciÃ³n en Google Colab con GPU T4

**Â¡Hora de comenzar los experimentos! ðŸš€**
