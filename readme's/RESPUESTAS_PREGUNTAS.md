# ðŸŽ¯ RESPUESTAS A TUS PREGUNTAS

## â“ Pregunta 1: Â¿CuÃ¡ntos aÃ±os de datos debo descargar?

### **Respuesta Directa:**

**Para PRUEBAS INICIALES:** Descarga **3 aÃ±os (2022-2024)**

**Para MODELO FINAL:** Descarga **10 aÃ±os (2014-2024)**

### **RecomendaciÃ³n EspecÃ­fica:**

```
FASE 1 (Semana 1-2): 
  â””â”€â†’ 3 aÃ±os: 2022, 2023, 2024
      â”œâ”€ TamaÃ±o: ~900 MB
      â”œâ”€ Tiempo: 4-5 horas total
      â””â”€ Objetivo: Validar que todo funciona

FASE 2 (Semana 3-4): 
  â””â”€â†’ 10 aÃ±os: 2014-2024
      â”œâ”€ TamaÃ±o: ~3.3 GB
      â”œâ”€ Tiempo: 16-19 horas total
      â””â”€ Objetivo: Modelo final para tesis
```

### **Â¿Por quÃ© empezar con 3 aÃ±os?**

âœ… **Ventajas:**
- Descarga rÃ¡pida (30 minutos)
- Puedes empezar HOY
- Suficiente para validar pipeline
- Identificar errores rÃ¡pido
- Ajustar hiperparÃ¡metros

âŒ **Si empiezas directo con 10 aÃ±os:**
- Si hay un error, pierdes 1 dÃ­a entero
- No puedes iterar rÃ¡pido
- Mayor riesgo de frustraciÃ³n

### **Mi RecomendaciÃ³n Personal:**

```
DÃA 1: Descargar 2023 y 2024 (ya los tienes!)
       â””â”€â†’ Renombrar cds_2023.zip â†’ era5_peru_2023.zip
       â””â”€â†’ Renombrar cds_2024.zip â†’ era5_peru_2024.zip
       â””â”€â†’ Descargar 2022 adicional

DÃA 2: Ejecutar pipeline completo con 3 aÃ±os

DÃA 3-4: Entrenar y validar

DÃA 5: SI TODO FUNCIONA â†’ Descargar 10 aÃ±os completos

SEMANA 2+: Entrenar modelo final
```

---

## â“ Pregunta 2: Â¿QuÃ© hacer con los datos CDS 2023 y 2024 que ya tengo?

### **Respuesta:**

**Â¡Ãšsalos! No necesitas re-descargarlos.**

### **Pasos:**

```bash
# 1. Renombrar archivos
mv cds_2023.zip era5_peru_2023.zip
mv cds_2024.zip era5_peru_2024.zip

# 2. Copiar a datasets/raw_era5/
cp era5_peru_2023.zip AdaptationOpenLTM/datasets/raw_era5/
cp era5_peru_2024.zip AdaptationOpenLTM/datasets/raw_era5/

# 3. Descargar solo 2022 adicional (para 3 aÃ±os)
# (seguir GUIA_DESCARGA_DATOS.md)

# 4. Ejecutar preprocesamiento
python preprocessing/preprocess_era5_peru.py \
    --years 2022,2023,2024
```

### **Verificar que sean los correctos:**

Tus archivos CDS deben contener:
- âœ… ResoluciÃ³n: 12-hourly (06:00, 18:00 UTC)
- âœ… 10 variables atmosfÃ©ricas
- âœ… RegiÃ³n: PerÃº (0Â°N a -18Â°S, -82Â°W a -68Â°W)
- âœ… Formato: NetCDF (.nc)

Si no estÃ¡s seguro, abre uno y verifica:

```python
import xarray as xr
ds = xr.open_dataset('era5_peru_2023.nc')
print(ds)  # Ver variables y dimensiones
```

---

## â“ Pregunta 3: Â¿Objetivo es predecir lluvia en 24 horas (no 3 horas)?

### **Respuesta:**

**âœ… YA ESTÃ IMPLEMENTADO ASÃ**

El cÃ³digo que creÃ© ya predice lluvia en las prÃ³ximas **24 horas** (RainTomorrow), NO 3 horas.

### **ConfiguraciÃ³n:**

En `preprocess_era5_peru.py`:

```python
# LÃ­nea de comando
--target_horizon 24  # 24 horas (default)

# Dentro del cÃ³digo
target_horizon = 24  # horas
horizon_steps = 24 // 12  # = 2 timesteps (porque resoluciÃ³n es 12h)
```

### **CÃ³mo funciona:**

```
Timestep actual: t
  â”œâ”€ Observaciones: [t-720d ... t]  (contexto)
  â””â”€ Target: Â¿Lluvia en t+24h?

Ejemplo concreto:
  â”œâ”€ Ahora: 2024-01-15 06:00
  â”œâ”€ Contexto: 2022-01-15 hasta 2024-01-15
  â””â”€ PredicciÃ³n: Â¿LloverÃ¡ el 2024-01-16 06:00? (24h despuÃ©s)
```

### **Si quisieras cambiar a otro horizonte:**

```python
# Para predecir lluvia en 48 horas
--target_horizon 48

# Para predecir lluvia en 12 horas
--target_horizon 12

# Para predecir lluvia en 1 semana
--target_horizon 168  # 7 dÃ­as * 24 horas
```

**Pero para tu tesis, quÃ©date con 24 horas** (es el estÃ¡ndar).

---

## â“ Pregunta 4: Â¿CÃ³mo ejecuto esto en Google Colab?

### **Respuesta:**

### **OpciÃ³n A: Usar el Notebook (MÃS FÃCIL)**

1. Subir `AdaptationOpenLTM` a GitHub
2. Abrir Google Colab: https://colab.research.google.com/
3. File â†’ Upload notebook
4. Seleccionar: `notebooks/colab_training_demo.ipynb`
5. Ejecutar celdas una por una
6. Â¡Listo!

### **OpciÃ³n B: Comandos Manuales**

```python
# ====== CELDA 1: Setup ======
!git clone https://github.com/TU_USUARIO/AdaptationOpenLTM.git
%cd AdaptationOpenLTM
!pip install -r requirements.txt

# ====== CELDA 2: Datos ======
from google.colab import drive
drive.mount('/content/drive')

# Subir archivos ERA5 (opciÃ³n 1: desde Drive)
!cp /content/drive/MyDrive/ERA5_Data/*.zip datasets/raw_era5/

# O subir manualmente (opciÃ³n 2)
from google.colab import files
uploaded = files.upload()  # Seleccionar era5_peru_*.zip
!mv era5_peru_*.zip datasets/raw_era5/

# ====== CELDA 3: Preprocesar ======
!python preprocessing/preprocess_era5_peru.py \
    --input_dir datasets/raw_era5 \
    --output_dir datasets/processed \
    --years 2023,2024 \
    --target_horizon 24

# ====== CELDA 4: Entrenar ======
!python run.py \
  --task_name forecast \
  --is_training 1 \
  --model timer_xl_classifier \
  --data PeruRainfall \
  --root_path datasets/processed/ \
  --data_path peru_rainfall.csv \
  --seq_len 1440 \
  --input_token_len 96 \
  --output_token_len 96 \
  --batch_size 128 \
  --learning_rate 1e-5 \
  --train_epochs 50 \
  --patience 10 \
  --use_focal_loss \
  --adaptation \
  --pretrain_model_path checkpoints/timer_xl/checkpoint.pth \
  --gpu 0 \
  --use_norm \
  --cosine \
  --checkpoints results/peru_rainfall/

# ====== CELDA 5: Guardar Resultados ======
!cp results/peru_rainfall/*/checkpoint.pth \
   /content/drive/MyDrive/timer_xl_checkpoints/best_model.pth
```

---

## â“ Pregunta 5: Â¿GPU T4 de Colab es suficiente?

### **Respuesta:**

**âœ… SÃ, perfectamente suficiente**

### **Especificaciones T4:**

```
GPU: NVIDIA Tesla T4
VRAM: 16 GB
Compute: 8.1 TFLOPS (FP32)

ComparaciÃ³n:
  RTX 3060:  12 GB VRAM  âŒ Menor
  RTX 3090:  24 GB VRAM  âœ… Mayor (pero cara)
  T4:        16 GB VRAM  âœ… Perfecto para este proyecto
```

### **Ajustes recomendados para T4:**

```python
# Para 3 aÃ±os de datos
batch_size = 256  # âœ… Funciona perfecto
seq_len = 1440    # âœ… 720 dÃ­as de contexto

# Para 10 aÃ±os de datos
batch_size = 128  # âœ… Reduce un poco
seq_len = 1440    # âœ… Mantener igual

# Si tienes OOM (Out of Memory):
batch_size = 64   # Reducir mÃ¡s
seq_len = 720     # O reducir contexto
```

### **Tiempos estimados en T4:**

```
3 aÃ±os:
  â””â”€ Preprocesamiento: ~15 min
  â””â”€ Entrenamiento (50 epochs): ~3-4 horas
  â””â”€ Total: ~4-5 horas

10 aÃ±os:
  â””â”€ Preprocesamiento: ~1.5 horas
  â””â”€ Entrenamiento (50 epochs): ~12-15 horas
  â””â”€ Total: ~14-17 horas
```

**IMPORTANTE:** Colab desconecta despuÃ©s de 12 horas. Para 10 aÃ±os:

```python
# Guardar checkpoint cada Ã©poca
# Ya implementado en el cÃ³digo
# Se guarda en results/peru_rainfall/

# Y copiar a Drive frecuentemente
!cp results/peru_rainfall/*/checkpoint.pth \
   /content/drive/MyDrive/timer_xl_checkpoints/backup_epoch_XX.pth
```

---

## â“ Pregunta 6: Â¿QuÃ© archivos subo a GitHub?

### **Respuesta:**

**SÃ subes:**
- âœ… Todo el cÃ³digo (`models/`, `preprocessing/`, etc.)
- âœ… Scripts de entrenamiento (`scripts/`)
- âœ… Notebooks (`notebooks/`)
- âœ… DocumentaciÃ³n (`*.md`)
- âœ… ConfiguraciÃ³n (`requirements.txt`, `.gitignore`)

**NO subes:**
- âŒ Datos ERA5 (archivos .zip, .nc) - muy grandes
- âŒ Checkpoints (.pth) - muy grandes
- âŒ Resultados (CSV, NPZ) - muy grandes

### **Estructura en GitHub:**

```
AdaptationOpenLTM/  (repo pÃºblico)
â”œâ”€â”€ cÃ³digo/         âœ… SUBIR
â”œâ”€â”€ documentaciÃ³n/  âœ… SUBIR
â”œâ”€â”€ datasets/raw_era5/     âŒ NO SUBIR (solo README.md)
â”œâ”€â”€ checkpoints/           âŒ NO SUBIR (solo .gitkeep)
â””â”€â”€ results/               âŒ NO SUBIR (solo .gitkeep)
```

### **Â¿DÃ³nde guardar datos grandes?**

```
Google Drive:
â””â”€ ERA5_Data/
   â”œâ”€ era5_peru_2023.zip       (subir aquÃ­)
   â”œâ”€ era5_peru_2024.zip
   â””â”€ ...

â””â”€ timer_xl_checkpoints/
   â”œâ”€ pretrained.pth           (descargar y subir aquÃ­)
   â””â”€ best_model.pth
```

### **En Colab, copiar desde Drive:**

```python
!cp /content/drive/MyDrive/ERA5_Data/*.zip datasets/raw_era5/
!cp /content/drive/MyDrive/timer_xl_checkpoints/pretrained.pth checkpoints/timer_xl/checkpoint.pth
```

---

## ðŸ“‹ CHECKLIST FINAL

### **Antes de empezar:**

- [ ] AdaptationOpenLTM subido a GitHub
- [ ] Checkpoint pre-entrenado descargado
- [ ] Archivos ERA5 2023, 2024 renombrados
- [ ] (Opcional) ERA5 2022 descargado
- [ ] Google Colab abierto
- [ ] Google Drive montado

### **Durante ejecuciÃ³n:**

- [ ] Datos preprocesados exitosamente
- [ ] Entrenamiento iniciado sin errores
- [ ] Loss decrece normalmente
- [ ] Checkpoints se guardan en Drive
- [ ] MÃ©tricas monitoreadas

### **DespuÃ©s de resultados:**

- [ ] F1-Score > 0.70 (mÃ­nimo)
- [ ] Confusion matrix analizada
- [ ] Resultados por regiÃ³n guardados
- [ ] Si exitoso â†’ Descargar 10 aÃ±os
- [ ] Experimentar con context lengths

---

## ðŸŽ“ CONCLUSIÃ“N

### **Tu Plan de AcciÃ³n Inmediato:**

```
HOY (DÃ­a 1):
  âœ“ Subir AdaptationOpenLTM a GitHub
  âœ“ Descargar checkpoint pre-entrenado
  âœ“ Renombrar cds_2023.zip y cds_2024.zip
  âœ“ Descargar ERA5 2022

MAÃ‘ANA (DÃ­a 2):
  âœ“ Ejecutar preprocesamiento
  âœ“ Iniciar entrenamiento en Colab

PASADO (DÃ­a 3-4):
  âœ“ Monitorear entrenamiento
  âœ“ Analizar primeros resultados

SIGUIENTE SEMANA:
  âœ“ SI EXITOSO â†’ Descargar 10 aÃ±os
  âœ“ Entrenar modelo final
```

### **Contacto para Dudas:**

Si tienes problemas, revisa:
1. `IMPLEMENTACION_COMPLETA.md` - GuÃ­a paso a paso
2. `GUIA_DESCARGA_DATOS.md` - Detalles de descarga
3. `README_PERU_RAINFALL.md` - Overview completo
4. `notebooks/colab_training_demo.ipynb` - Demo ejecutable

---

**Â¡TODO CLARO! ðŸš€**

Tu siguiente paso es:
1. Subir a GitHub
2. Descargar checkpoint
3. Ejecutar en Colab

**Tiempo estimado hasta primeros resultados: 1 dÃ­a**

Â¡Ã‰xitos con tu tesis! ðŸŽ“
