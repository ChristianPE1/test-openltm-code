# üéì Plan de Acci√≥n Final para Tesis Timer-XL

**Fecha**: 2025-01-11  
**Autor**: Christian  
**Estado**: Fase de Decisi√≥n Estrat√©gica

---

## üìä Resultados Actuales (COMPLETADO)

### Modelos Entrenados

| Modelo | F1-Score | Precision | Recall | Accuracy | Tiempo | VRAM |
|--------|----------|-----------|--------|----------|--------|------|
| **Transfer Learning** | **0.79** ‚úÖ | 0.71 | **0.89** ‚úÖ | 72.87% | 60 min (5 √©pocas) | 8 GB |
| **Small Model** | **0.78** | **0.87** ‚úÖ | 0.70 | **76.93%** ‚úÖ | 15 min | 1.5 GB |
| Big Scratch | ~0.55 | - | - | 57.98% | 40 min | 6 GB |

### ‚úÖ Hallazgos Clave

1. **Transfer Learning (F1=0.79)**: 
   - Mayor recall (89%) ‚Üí mejor detecci√≥n de lluvias
   - Menor precisi√≥n (71%) ‚Üí m√°s falsos positivos (49%)
   - Solo 5 √©pocas ‚Üí **TIENE POTENCIAL DE MEJORA**

2. **Small Model (F1=0.78)**:
   - Mayor precisi√≥n (87%) ‚Üí menos falsos positivos (14%)
   - Menor recall (70%) ‚Üí pierde m√°s eventos reales
   - Ultra eficiente ‚Üí 4x m√°s r√°pido

3. **Zona intermedia (0.75 < F1 < 0.80)**: 
   - No es "excelente" pero tampoco "malo"
   - Permite dos caminos v√°lidos para la tesis

---

## üéØ DECISI√ìN ESTRAT√âGICA: Dos Caminos Posibles

### ‚≠ê **OPCI√ìN A: Mejoras Arquitect√≥nicas (RECOMENDADO)**

**Raz√≥n**: F1=0.79 es mejorable con optimizaciones y modificaciones arquitect√≥nicas

#### Objetivo de Tesis
> *"Optimizaci√≥n de Timer-XL mediante mejoras en TimeAttention y transfer learning para predicci√≥n de lluvias con influencia ENSO, logrando F1-Score > 0.85"*

### Plan de Trabajo (3-4 semanas)

### **Semana 1: Optimizaci√≥n de Transfer Learning Actual**

**Objetivo**: Mejorar F1 de 0.79 a 0.82+ con ajustes simples

**Experimentos**:

1. **Entrenar m√°s √©pocas** (15-20 √©pocas totales)
   ```bash
   # Continuar desde checkpoint actual
   python run.py \
     --task_name classification \
     --model timer_xl_classifier \
     --train_epochs 20 \
     --learning_rate 5e-6 \  # Reducir LR para fine-tuning
     --adaptation \
     --pretrain_model_path checkpoints/.../checkpoint.pth
   ```
   - **Expectativa**: F1 ‚Üí 0.81-0.82
   - **Tiempo**: 3 horas (15 √©pocas adicionales)

2. **Optimizar Class Weights** para balancear Precision-Recall
   ```python
   # En timer_xl_classifier.py
   class_weights = [1.5, 1.0]  # Penalizar m√°s No Rain
   criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights))
   ```
   - **Expectativa**: Reducir falsos positivos de 49% ‚Üí 35%
   - **F1 esperado**: 0.82-0.83

3. **Learning Rate Schedule optimizado**
   ```python
   # Cosine annealing con warmup
   scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)
   ```
   - **Expectativa**: Convergencia m√°s estable
   - **F1 esperado**: 0.83-0.84

### **Semana 2: Modificaciones Arquitect√≥nicas en Timer-XL**

**Objetivo**: Mejorar captura de patrones ENSO con mejoras espec√≠ficas

**Experimento 1: ENSO-Aware TimeAttention**

Modificar `layers/SelfAttention_Family.py` para incluir phase embeddings:

```python
class ENSOAwareTimeAttention(TimeAttention):
    def __init__(self, d_model, n_heads, enso_dim=3):
        super().__init__(d_model, n_heads)
        # Embeddings para fases ENSO (El Ni√±o, La Ni√±a, Neutral)
        self.enso_embedding = nn.Embedding(3, enso_dim)
        self.enso_projection = nn.Linear(d_model + enso_dim, d_model)
        
    def forward(self, x, enso_phase):
        # x: [B, L, D]
        # enso_phase: [B] (0=Neutral, 1=El Ni√±o, 2=La Ni√±a)
        
        # 1. Agregar ENSO embeddings
        enso_emb = self.enso_embedding(enso_phase).unsqueeze(1)  # [B, 1, enso_dim]
        enso_emb = enso_emb.expand(-1, x.size(1), -1)  # [B, L, enso_dim]
        
        # 2. Concatenar y proyectar
        x_enso = torch.cat([x, enso_emb], dim=-1)  # [B, L, D+enso_dim]
        x_enso = self.enso_projection(x_enso)  # [B, L, D]
        
        # 3. Aplicar TimeAttention original
        return super().forward(x_enso)
```

**Expectativa**: F1 ‚Üí 0.84-0.85 (mejor en fases ENSO extremas)

**Experimento 2: M√°scara Kronecker Adaptativa**

Modificar `layers/Attn_Bias.py` para ajustar m√°scara seg√∫n fase ENSO:

```python
class AdaptiveKroneckerMask(KroneckerMask):
    def forward(self, x, enso_phase):
        # Generar m√°scara base
        mask = super().forward(x)
        
        # Ajustar seg√∫n fase ENSO
        if enso_phase in [1, 2]:  # El Ni√±o o La Ni√±a
            # Aumentar receptive field para eventos extremos
            mask = self.expand_mask(mask, factor=1.5)
        
        return mask
```

**Expectativa**: Mejor captura de patrones de largo plazo ‚Üí F1 ‚Üí 0.85+

**Experimento 3: Multi-Scale Temporal Features**

Agregar m√≥dulo de extracci√≥n multi-escala antes de TimeAttention:

```python
class MultiScaleTemporalModule(nn.Module):
    def __init__(self, d_model):
        super().__init__()
        # Convoluciones con diferentes receptive fields
        self.conv_daily = nn.Conv1d(d_model, d_model//3, kernel_size=24)  # 1 d√≠a
        self.conv_weekly = nn.Conv1d(d_model, d_model//3, kernel_size=168)  # 7 d√≠as
        self.conv_monthly = nn.Conv1d(d_model, d_model//3, kernel_size=720)  # 30 d√≠as
        
    def forward(self, x):
        # x: [B, L, D]
        x_t = x.transpose(1, 2)  # [B, D, L]
        
        feat_daily = self.conv_daily(x_t)
        feat_weekly = self.conv_weekly(x_t)
        feat_monthly = self.conv_monthly(x_t)
        
        # Concatenar caracter√≠sticas multi-escala
        feat_multi = torch.cat([feat_daily, feat_weekly, feat_monthly], dim=1)
        return feat_multi.transpose(1, 2)  # [B, L', D]
```

**Expectativa**: Capturar mejor la estacionalidad ‚Üí F1 ‚Üí 0.86+

### **Semana 3: Ablation Studies y Validaci√≥n**

**Objetivo**: Demostrar que cada mejora contribuye al rendimiento

**Experimentos**:

1. **Baseline**: Transfer Learning original (F1=0.79)
2. **+ M√°s √©pocas**: F1 esperado 0.82
3. **+ Class weights**: F1 esperado 0.83
4. **+ ENSO-aware attention**: F1 esperado 0.85
5. **+ M√°scara adaptativa**: F1 esperado 0.85
6. **+ Multi-scale**: F1 esperado 0.86
7. **Todos juntos**: F1 esperado **0.87-0.88** ‚úÖ

**Tabla de Resultados**:

| Configuraci√≥n | F1-Score | Precision | Recall | ŒîF1 vs Baseline |
|---------------|----------|-----------|--------|-----------------|
| Baseline (Transfer Learning) | 0.79 | 0.71 | 0.89 | - |
| + 15 √©pocas | 0.82 | 0.75 | 0.90 | +0.03 |
| + Class weights | 0.83 | 0.80 | 0.86 | +0.04 |
| + ENSO-aware attention | 0.85 | 0.82 | 0.88 | +0.06 |
| + M√°scara adaptativa | 0.85 | 0.83 | 0.87 | +0.06 |
| + Multi-scale | 0.86 | 0.84 | 0.88 | +0.07 |
| **TODO** | **0.87** | **0.85** | **0.89** | **+0.08** ‚úÖ |

##### **Semana 4: Validaci√≥n ENSO y Escritura**

**Objetivo**: Validar que mejoras funcionan en todas las fases ENSO

1. **Etiquetar datos por fase ENSO**:
   ```python
   # Descargar ONI index 2020-2024
   # Clasificar cada sample: El Ni√±o (1), La Ni√±a (2), Neutral (0)
   ```

2. **Evaluar modelo mejorado por fase**:
   ```
   F1 El Ni√±o:   0.85-0.87
   F1 La Ni√±a:   0.87-0.89
   F1 Neutral:   0.86-0.88
   ```

3. **Escribir Metodolog√≠a + Resultados**:
   - Descripci√≥n de cada mejora arquitect√≥nica
   - Ablation studies con gr√°ficos
   - Validaci√≥n ENSO
   - Conclusiones

---

### üî¨ **OPCI√ìN B: An√°lisis ENSO + Contexto Temporal**

**Raz√≥n**: F1=0.79 es suficiente para an√°lisis robusto de contexto √≥ptimo

#### Objetivo de Tesis
> *"Determinaci√≥n del contexto temporal √≥ptimo para predicci√≥n de lluvias con influencia ENSO usando Timer-XL, validando rendimiento por fase clim√°tica"*

### Plan de Trabajo (2-3 semanas)

### **Semana 1: Etiquetado ENSO y Validaci√≥n por Fase**

1. **Descargar √≠ndice ONI** (Oceanic Ni√±o Index 2020-2024)
2. **Etiquetar cada muestra** con fase ENSO
3. **Evaluar Small Model por fase**:
   ```
   F1 El Ni√±o:   ?
   F1 La Ni√±a:   ?
   F1 Neutral:   ?
   ```

### **Semana 2: Experimentos de Contexto**

Entrenar Small Model con 5 longitudes de contexto:

```bash
for seq_len in 90 180 365 730 1095; do
  python run.py \
    --seq_len $((seq_len * 24)) \  # D√≠as a horas
    --model_id "context_${seq_len}days"
done
```

**An√°lisis de saturaci√≥n**:
- ¬øEn qu√© punto mejora < 2% con m√°s contexto?
- ¬øFases ENSO requieren diferentes contextos?

### **Semana 3: An√°lisis y Escritura**

1. **Gr√°ficos**: F1 vs Contexto por fase ENSO
2. **Conclusi√≥n**: "Contexto √≥ptimo = 365-730 d√≠as"
3. **Contribuci√≥n**: Reproducible pero menos novedosa

---

## üéØ MI RECOMENDACI√ìN: **OPCI√ìN A** (Mejoras Arquitect√≥nicas)

### Razones

1. ‚úÖ **Mayor aporte al estado del arte**:
   - Mejoras en TimeAttention (ENSO-aware)
   - M√°scara Kronecker adaptativa
   - Multi-scale temporal features

2. ‚úÖ **F1=0.79 es mejorable**:
   - Solo 5 √©pocas ‚Üí puede llegar a 0.82+ con m√°s entrenamiento
   - Modificaciones arquitect√≥nicas ‚Üí 0.85-0.88

3. ‚úÖ **Transfer Learning tiene potencial**:
   - Recall=0.89 demuestra que captura patrones
   - Precisi√≥n baja (0.71) es optimizable con class weights

4. ‚úÖ **Contribuci√≥n m√°s s√≥lida para tesis**:
   - "Optimized Timer-XL achieves F1=0.87" > "Optimal context is 730 days"

5. ‚úÖ **Timeline realista**: 3-4 semanas vs 2-3 semanas (similar esfuerzo)

---

## üìã Pasos Inmediatos (Esta Semana)

### ‚úÖ Paso 1: Continuar Entrenamiento Transfer Learning (Hoy)

```bash
# Cargar checkpoint actual y entrenar 15 √©pocas m√°s
python run.py \
  --task_name classification \
  --model timer_xl_classifier \
  --train_epochs 20 \
  --learning_rate 5e-6 \
  --adaptation \
  --pretrain_model_path checkpoints/classification_peru_rainfall_timerxl_.../checkpoint.pth
```

**Expectativa**: F1 ‚Üí 0.81-0.82 (2-3 horas)

### ‚úÖ Paso 2: Implementar Class Weights (Ma√±ana)

Modificar `models/timer_xl_classifier.py`:

```python
# En __init__
self.class_weights = torch.tensor([1.5, 1.0]).to(device)  # Penalizar m√°s No Rain
self.criterion = nn.CrossEntropyLoss(weight=self.class_weights)
```

Entrenar de nuevo y medir impacto:
- Falsos positivos: 49% ‚Üí ~35%
- Precision: 0.71 ‚Üí ~0.78
- F1: 0.82 ‚Üí ~0.83

### ‚úÖ Paso 3: Validar Mejora (2 d√≠as)

Comparar:
- Transfer Learning 5 √©pocas (F1=0.79)
- Transfer Learning 20 √©pocas (F1=~0.82)
- Transfer Learning 20 √©pocas + class weights (F1=~0.83)

Si F1 > 0.83: ‚úÖ **Confirmar OPCI√ìN A y proceder con mejoras arquitect√≥nicas**

---

## üìä M√©tricas de √âxito para Tesis

### M√≠nimo Aceptable
- F1-Score > 0.82 (mejora de 3% sobre baseline 0.79)
- Ablation studies mostrando contribuci√≥n de cada mejora
- Validaci√≥n en 3 fases ENSO

### Objetivo Ideal
- F1-Score > 0.85 (mejora de 6% sobre baseline)
- Precision > 0.82 (reducci√≥n de falsos positivos)
- Recall > 0.85 (mantener detecci√≥n alta)
- Consistencia en fases ENSO (|ŒîF1| < 0.10)

### Excelente (Publicable)
- F1-Score > 0.87 (mejora de 8%)
- Precision > 0.85 y Recall > 0.89
- Superioridad demostrada vs Small Model en todas las m√©tricas
- C√≥digo reproducible + ablation studies completos

---

## üìù Estructura de Tesis Propuesta

### Cap√≠tulo 1: Introducci√≥n
- Motivaci√≥n: ENSO y predicci√≥n de lluvias en Per√∫
- Problema: Modelos actuales tienen F1 < 0.80
- **Contribuci√≥n**: "Optimizaci√≥n de Timer-XL con mejoras arquitect√≥nicas para F1 > 0.85"

### Cap√≠tulo 2: Marco Te√≥rico
- 2.1 Fen√≥meno ENSO
- 2.2 Arquitectura Transformer
- 2.3 Timer-XL: TimeAttention y m√°scara Kronecker
- 2.4 Transfer Learning en series temporales

### Cap√≠tulo 3: Metodolog√≠a
- 3.1 Datos ERA5 (2020-2024)
- 3.2 Baseline: Transfer Learning (F1=0.79)
- 3.3 Mejoras propuestas:
  - ENSO-aware TimeAttention
  - M√°scara Kronecker adaptativa
  - Multi-scale temporal features
  - Optimizaci√≥n de hiperpar√°metros
- 3.4 Ablation studies

### Cap√≠tulo 4: Resultados
- 4.1 Comparaci√≥n Baseline vs Mejorado
- 4.2 Ablation studies (contribuci√≥n individual)
- 4.3 Validaci√≥n por fase ENSO
- 4.4 An√°lisis de casos (aciertos/errores)

### Cap√≠tulo 5: Discusi√≥n
- Por qu√© ENSO-aware attention mejora F1
- Trade-off Precision-Recall
- Limitaciones y trabajo futuro

### Cap√≠tulo 6: Conclusiones
- Timer-XL optimizado logra F1=0.87 (+8% vs baseline)
- ENSO-aware attention es clave para eventos extremos
- Pipeline reproducible para predicci√≥n clim√°tica

---

## üöÄ Pr√≥ximos Pasos (Esta Semana)

1. **Hoy (S√°bado)**:
   - [x] Analizar resultados Transfer Learning (COMPLETADO)
   - [ ] Continuar entrenamiento 15 √©pocas m√°s
   - [ ] Monitorear convergencia

2. **Ma√±ana (Domingo)**:
   - [ ] Implementar class weights
   - [ ] Entrenar con class weights
   - [ ] Comparar F1: baseline (0.79) vs nuevo (~0.83)

3. **Lunes-Martes**:
   - [ ] Si F1 > 0.83: Implementar ENSO-aware TimeAttention
   - [ ] Si F1 < 0.82: Revisar learning rate / epochs

4. **Mi√©rcoles-Jueves**:
   - [ ] Implementar m√°scara Kronecker adaptativa
   - [ ] Entrenar y validar

5. **Viernes**:
   - [ ] Revisar progreso con asesor
   - [ ] Decidir si continuar con multi-scale o consolidar resultados

---

## üìß Preguntas para Asesor (Pr√≥xima Reuni√≥n)

1. **Alcance de tesis**: ¬øAceptable enfoque de mejoras arquitect√≥nicas vs an√°lisis de contexto?

2. **M√©tricas objetivo**: ¬øF1 > 0.85 es suficiente para tesis o necesito > 0.87?

3. **Validaci√≥n ENSO**: ¬øTemporal split (2020-2022 train, 2023-2024 test) o stratified?

4. **Contribuci√≥n novedosa**: ¬øENSO-aware TimeAttention es suficiente aporte o necesito m√°s?

5. **Timeline**: ¬ø3-4 semanas es realista o debo simplificar experimentos?

---

**√öltima Actualizaci√≥n**: 2025-01-11  
**Estado**: Plan definido, esperando inicio de Opci√≥n A  
**Meta**: F1-Score > 0.85 con mejoras arquitect√≥nicas
