# üö® An√°lisis: Entrenamientos Fallidos (11 A√±os, 13/Oct/2025)

**Fecha**: 2025-10-13  
**Dataset**: 11 a√±os (2014-2024), 28,119 timesteps  
**Problema**: Ambos modelos consumieron MUCHA m√°s VRAM y tiempo de lo esperado

---

## üìä Resultados Observados vs Esperados

### Transfer Learning (8L, 1024D, seq_len=2880)

| M√©trica | Esperado | Real | Diferencia |
|---------|----------|------|------------|
| **VRAM** | ~6 GB | **10 GB** | +67% ‚ùå |
| **Tiempo/√©poca** | ~30 min | **~65 min** | +117% ‚ùå |
| **Tiempo total** | 15-20 horas | **32.5 horas** | +62% ‚ùå |
| **Val Accuracy √âpoca 1** | ~78-80% | **69.05%** | -11% ‚ùå |
| **Val Accuracy √âpoca 2** | Mejora | **69.05%** (igual) | Estancado ‚ùå |
| **Val Loss √âpoca 1** | 0.035-0.040 | **0.0393** | OK ‚úÖ |
| **Val Loss √âpoca 2** | Mejora | **0.0395** ‚Üë | Empeor√≥ ‚ùå |

**Logs completos**:
```
Epoch 1 cost time: 3897.7179651260376 (64.96 min)
Val Accuracy: 69.05% (4160/6025)
Test Accuracy: 63.34% (3817/6026)
Vali Loss: 0.0392924, Test Loss: 0.0413758

Epoch 2 cost time: 3881.464823484421 (64.69 min)
Val Accuracy: 69.05% (4160/6025)  # ‚ö†Ô∏è ID√âNTICO A √âPOCA 1
Test Accuracy: 63.34% (3817/6026)  # ‚ö†Ô∏è ID√âNTICO A √âPOCA 1
Vali Loss: 0.0394477, Test Loss: 0.0413155
EarlyStopping counter: 1 out of 8
```

**Diagn√≥stico**: 
- ‚ùå Accuracy **exactamente igual** en √©pocas 1 y 2 (69.05%) indica **convergencia bloqueada**
- ‚ùå Val Loss sube ligeramente (0.0393 ‚Üí 0.0395) = no aprende
- ‚ùå `seq_len=2880` (120 d√≠as) es **demasiado largo** para optimizar
- ‚ùå `batch_size=12` con secuencias largas ‚Üí 10 GB VRAM

---

### Small Model "Mejorado" (6L, 768D, seq_len=1440)

| M√©trica | Esperado | Real | Diferencia |
|---------|----------|------|------------|
| **VRAM** | ~2-3 GB | **6 GB** | +200% ‚ùå |
| **Tiempo/√©poca** | ~5-8 min | **~14 min** | +75-180% ‚ùå |
| **Tiempo total** | 2-3 horas | **5.8 horas** | +93% ‚ùå |
| **Val Accuracy √âpoca 1** | ~75-78% | **75.40%** | OK ‚úÖ |
| **Val Accuracy √âpoca 2** | Mejora | **70.29%** ‚Üì | -5.1% ‚ùå |
| **Val Accuracy √âpoca 3** | Mejora | **75.42%** | Inestable ‚ùå |
| **Val Loss √âpoca 1** | 0.035-0.040 | **0.0356** | OK ‚úÖ |
| **Val Loss √âpoca 2** | Mejora | **0.0381** ‚Üë | Empeor√≥ ‚ùå |
| **Val Loss √âpoca 3** | Mejora | **0.0372** | Empeor√≥ ‚ùå |

**Logs completos**:
```
Epoch 1 cost time: 860.0865225791931 (14.33 min)
Val Accuracy: 75.40% (4543/6025)
Test Accuracy: 76.22% (4593/6026)
Vali Loss: 0.0355761, Test Loss: 0.0321258

Epoch 2 cost time: 866.5918929576874 (14.44 min)
Val Accuracy: 70.29% (4235/6025)  # ‚ö†Ô∏è EMPEOR√ì -5.1%
Test Accuracy: 72.49% (4368/6026)  # ‚ö†Ô∏è EMPEOR√ì -3.7%
Vali Loss: 0.0380584, Test Loss: 0.0342675
EarlyStopping counter: 1 out of 8

Epoch 3 cost time: 865.8048624992371 (14.43 min)
Val Accuracy: 75.42% (4544/6025)  # ‚ö†Ô∏è Volvi√≥ pero inestable
Test Accuracy: 70.11% (4225/6026)  # ‚ö†Ô∏è EMPEOR√ì -6.1%
Vali Loss: 0.0372419, Test Loss: 0.0420861
EarlyStopping counter: 2 out of 8
```

**Diagn√≥stico**: 
- ‚ùå Val/Test Accuracy **oscila violentamente** (75% ‚Üí 70% ‚Üí 75%)
- ‚ùå Test Accuracy **diverge** de Val Accuracy (diferencia de 5.3% en √©poca 3)
- ‚ùå Val Loss **no mejora** despu√©s de √©poca 1 (0.0356 ‚Üí 0.0381 ‚Üí 0.0372)
- ‚ùå Modelo "Small" usa **6 GB VRAM** = dej√≥ de ser "small"
- ‚ö†Ô∏è Overfitting temprano: mejora en √©poca 1, empeora en √©pocas 2-3

---

## üîç An√°lisis Detallado: ¬øQu√© Sali√≥ Mal?

### Problema 1: seq_len Demasiado Largo (Transfer Learning)

**Configuraci√≥n problem√°tica**:
```python
seq_len = 2880  # 120 d√≠as √ó 24 horas
batch_size = 12
```

**Memoria GPU requerida**:
```
Memory = batch_size √ó seq_len √ó d_model √ó e_layers √ó overhead
        = 12 √ó 2880 √ó 1024 √ó 8 √ó 1.5 (gradients, activations, optimizer states)
        ‚âà 10 GB
```

**Por qu√© 120 d√≠as es excesivo**:
1. ‚ùå **Optimizaci√≥n lenta**: Backpropagation a trav√©s de 2880 timesteps es computacionalmente intenso
2. ‚ùå **Vanishing gradients**: Se√±al de gradiente se debilita con secuencias muy largas
3. ‚ùå **Overfitting local**: Modelo memoriza patrones espec√≠ficos de 120 d√≠as en lugar de generalizar
4. ‚ùå **Convergencia bloqueada**: Accuracy id√©ntica en √©pocas 1-2 (69.05%) indica que no optimiza

**Evidencia emp√≠rica (con 5 a√±os de datos)**:
- Con `seq_len=1440` (60 d√≠as) lograste **F1=0.79, Val Acc ~80%**
- Con `seq_len=2880` (120 d√≠as) solo lograste **Val Acc=69.05%** (estancado)
- **Conclusi√≥n**: M√°s contexto NO siempre es mejor

---

### Problema 2: Small Model Dej√≥ de Ser "Small"

**Comparaci√≥n de arquitecturas**:

| Modelo | Layers | d_model | Par√°metros | VRAM | Tiempo/√©poca |
|--------|--------|---------|------------|------|--------------|
| **Small Original (5 a√±os)** | 4 | 512 | ~20M | 1.5 GB | ~5 min |
| **Small "Mejorado" (11 a√±os)** | 6 | 768 | ~60M | **6 GB** | **~14 min** |
| **Transfer Learning** | 8 | 1024 | ~100M | 6 GB (esperado) | ~30 min |

**An√°lisis**:
- ‚ùå Small "Mejorado" creci√≥ **+300% VRAM** (1.5 GB ‚Üí 6 GB)
- ‚ùå Par√°metros aumentaron **+200%** (20M ‚Üí 60M)
- ‚ùå Casi tan grande como Transfer Learning (60M vs 100M par√°metros)
- ‚ùå Perdi√≥ su ventaja principal: **eficiencia para experimentos r√°pidos**

**Por qu√© 6 layers, 768 dim fue excesivo**:
1. ‚ùå **Overfitting temprano**: Val Loss empeor√≥ en √©pocas 2-3
2. ‚ùå **Inestabilidad**: Val Accuracy oscila 75% ‚Üí 70% ‚Üí 75%
3. ‚ùå **Test diverge de Val**: Diferencia de 5.3% en √©poca 3 (overfitting)
4. ‚ùå **Recursos desperdiciados**: 6 GB VRAM sin beneficio claro

---

### Problema 3: Desbalance Class Distribution en Splits

**Class distribution observada**:
```python
# Transfer Learning (seq_len=2880)
[TRAIN] Class distribution: No Rain=9657, Rain=18462  # 34% / 66%
[VAL]   Class distribution: No Rain=2490, Rain=6415   # 28% / 72% ‚ö†Ô∏è
[TEST]  Class distribution: No Rain=3208, Rain=5698   # 36% / 64%

# Small Model (seq_len=1440)
[TRAIN] Class distribution: No Rain=9657, Rain=18462  # 34% / 66%
[VAL]   Class distribution: No Rain=2173, Rain=5292   # 29% / 71% ‚ö†Ô∏è
[TEST]  Class distribution: No Rain=2739, Rain=4727   # 37% / 63%
```

**An√°lisis**:
- ‚ö†Ô∏è Train: 66% Rain, Val: 71-72% Rain ‚Üí **Val m√°s desbalanceado que Train**
- ‚ö†Ô∏è Esto puede causar que modelo optimice para mayor√≠a (Rain) en Val
- ‚ö†Ô∏è Test tiene mejor distribuci√≥n (63-64% Rain) pero a√∫n desbalanceado

**Impacto**:
- Val Loss puede ser enga√±oso (optimiza para clase mayoritaria)
- F1-Score es mejor m√©trica que Accuracy en este caso
- Early stopping basado en Val Loss puede ser sub√≥ptimo

---

## üéØ Configuraciones Corregidas (Urgente)

### ‚úÖ Transfer Learning Optimizado (RECOMENDADO)

**Cambios cr√≠ticos**:
```python
# ANTES (10 GB VRAM, 65 min/√©poca)
seq_len = 2880        # ‚ùå Demasiado largo
batch_size = 12       # ‚ùå Ineficiente
learning_rate = 5e-5

# DESPU√âS (5-6 GB VRAM, 25-30 min/√©poca)
seq_len = 1440        # ‚úÖ 60 d√≠as (suficiente para ENSO)
batch_size = 16       # ‚úÖ M√°s eficiente
learning_rate = 5e-5  # Sin cambios
```

**Justificaci√≥n seq_len=1440 (60 d√≠as)**:
1. ‚úÖ Captura 2 meses completos de patrones atmosf√©ricos
2. ‚úÖ Incluye transiciones ENSO (El Ni√±o ‚Üí Neutral en ~1-2 meses)
3. ‚úÖ Con 5 a√±os + seq_len=1440 lograste F1=0.79
4. ‚úÖ 120 d√≠as caus√≥ convergencia bloqueada (Val Acc=69.05% estancado)

**Recursos esperados**:
- VRAM: ~5-6 GB ‚úÖ (reducci√≥n de 40%)
- Tiempo/√©poca: ~25-30 min ‚úÖ (reducci√≥n de 54%)
- Tiempo total: 12-15 horas ‚úÖ (viable en Colab)

**Configuraci√≥n completa**:
```bash
python run.py \
  --model timer_xl_classifier \
  --seq_len 1440 \              # ‚≠ê CAMBIO CR√çTICO
  --e_layers 8 \
  --d_model 1024 \
  --d_ff 2048 \
  --n_heads 8 \
  --batch_size 16 \             # ‚≠ê CAMBIO CR√çTICO
  --learning_rate 5e-5 \
  --dropout 0.2 \
  --train_epochs 30 \
  --adaptation \
  --pretrain_model_path checkpoints/timer_xl/checkpoint.pth
```

---

### ‚úÖ Small Model REALMENTE Eficiente (RECOMENDADO)

**Cambios cr√≠ticos**:
```python
# ANTES (6 GB VRAM, 14 min/√©poca, overfitting)
e_layers = 6          # ‚ùå Demasiadas capas
d_model = 768         # ‚ùå Demasiado grande
d_ff = 1536
batch_size = 24

# DESPU√âS (3-4 GB VRAM, 8-10 min/√©poca)
e_layers = 5          # ‚úÖ Punto medio
d_model = 640         # ‚úÖ Entre 512 y 768
d_ff = 1280           # ‚úÖ Proporcional
batch_size = 32       # ‚úÖ M√°s eficiente
```

**Justificaci√≥n (5 layers, 640 dim)**:
1. ‚úÖ Mantiene capacidad para 11 a√±os de datos (~40M par√°metros)
2. ‚úÖ Reduce VRAM a 3-4 GB (realmente "small")
3. ‚úÖ M√°s estable que 6L/768D (menos overfitting)
4. ‚úÖ Permite experimentos r√°pidos (3-4 horas total)

**Recursos esperados**:
- VRAM: ~3-4 GB ‚úÖ (reducci√≥n de 33%)
- Tiempo/√©poca: ~8-10 min ‚úÖ (reducci√≥n de 29%)
- Tiempo total: 3-4 horas ‚úÖ (muy manejable)

**Configuraci√≥n completa**:
```bash
python run.py \
  --model timer_xl_classifier \
  --seq_len 1440 \
  --e_layers 5 \                # ‚≠ê CAMBIO CR√çTICO
  --d_model 640 \               # ‚≠ê CAMBIO CR√çTICO
  --d_ff 1280 \                 # ‚≠ê CAMBIO CR√çTICO
  --n_heads 8 \
  --batch_size 32 \             # ‚≠ê CAMBIO CR√çTICO
  --learning_rate 8e-5 \
  --dropout 0.15 \
  --train_epochs 25
```

---

## üìä Comparaci√≥n: Antes vs Despu√©s

### Transfer Learning

| Aspecto | Antes (Fallido) | Despu√©s (Corregido) | Mejora |
|---------|-----------------|---------------------|--------|
| **seq_len** | 2880 (120 d√≠as) | 1440 (60 d√≠as) | -50% |
| **batch_size** | 12 | 16 | +33% |
| **VRAM** | 10 GB ‚ùå | 5-6 GB ‚úÖ | -40% |
| **Tiempo/√©poca** | 65 min ‚ùå | 25-30 min ‚úÖ | -54% |
| **Tiempo total** | 32.5 horas ‚ùå | 12-15 horas ‚úÖ | -54% |
| **Val Acc √©poca 1** | 69.05% ‚ùå | ~78-80% ‚úÖ | +9-11% |
| **Convergencia** | Estancado ‚ùå | Esperada ‚úÖ | ‚úÖ |

---

### Small Model

| Aspecto | Antes (Fallido) | Despu√©s (Corregido) | Mejora |
|---------|-----------------|---------------------|--------|
| **e_layers** | 6 | 5 | -17% |
| **d_model** | 768 | 640 | -17% |
| **d_ff** | 1536 | 1280 | -17% |
| **batch_size** | 24 | 32 | +33% |
| **VRAM** | 6 GB ‚ùå | 3-4 GB ‚úÖ | -33% |
| **Tiempo/√©poca** | 14 min ‚ùå | 8-10 min ‚úÖ | -29% |
| **Tiempo total** | 5.8 horas ‚ö†Ô∏è | 3-4 horas ‚úÖ | -31% |
| **Val Acc estabilidad** | Oscila ¬±5% ‚ùå | Esperada estable ‚úÖ | ‚úÖ |
| **Overfitting** | Temprano ‚ùå | Reducido ‚úÖ | ‚úÖ |

---

## üî¨ Lecciones Aprendidas

### 1. M√°s datos ‚â† Secuencias m√°s largas
- ‚úÖ 11 a√±os de datos (28,119 timesteps) est√° bien
- ‚ùå seq_len=2880 (120 d√≠as) es contraproducente
- ‚úÖ seq_len=1440 (60 d√≠as) es √≥ptimo (equilibrio contexto/optimizaci√≥n)

### 2. "Mejorado" no significa "m√°s grande siempre"
- ‚ùå 6 layers, 768 dim = 6 GB VRAM (casi como Transfer Learning)
- ‚úÖ 5 layers, 640 dim = 3-4 GB VRAM (eficiente pero capaz)
- ‚úÖ Mantiene identidad "small" para experimentos r√°pidos

### 3. Se√±ales de problemas de convergencia
- ‚ùå Val Accuracy id√©ntica en m√∫ltiples √©pocas (Transfer: 69.05% √©pocas 1-2)
- ‚ùå Val Accuracy oscila violentamente (Small: 75% ‚Üí 70% ‚Üí 75%)
- ‚ùå Test diverge de Val (Small: diferencia 5.3% en √©poca 3)
- ‚úÖ Detener entrenamiento temprano si se observan estas se√±ales

### 4. Class imbalance requiere m√©tricas adecuadas
- ‚ö†Ô∏è Val tiene 71-72% Rain (m√°s desbalanceado que Train 66%)
- ‚ö†Ô∏è Accuracy puede ser enga√±osa (modelo predice "Rain" siempre = 71% Acc)
- ‚úÖ F1-Score, Precision, Recall son mejores m√©tricas
- ‚úÖ Use Focal Loss (ya configurado) para manejo de desbalance

---

## üöÄ Pr√≥ximos Pasos (Inmediato)

### Paso 1: Actualizar notebook (COMPLETADO ‚úÖ)
- ‚úÖ Transfer Learning: seq_len=2880 ‚Üí 1440, batch_size=12 ‚Üí 16
- ‚úÖ Small Model: 6L/768D ‚Üí 5L/640D, batch_size=24 ‚Üí 32

### Paso 2: Re-entrenar con configuraciones corregidas

**Prioridad 1: Transfer Learning** (12-15 horas)
```bash
# Usar celda actualizada en colab_training_demo.ipynb
# Configuraci√≥n: 8L, 1024D, seq_len=1440, batch_size=16
# Meta: F1 > 0.82, Val Acc > 78%
```

**Prioridad 2: Small Model Eficiente** (3-4 horas)
```bash
# Usar celda actualizada en colab_training_demo.ipynb
# Configuraci√≥n: 5L, 640D, seq_len=1440, batch_size=32
# Meta: F1 > 0.80, Val Acc > 75%
```

### Paso 3: Monitoreo de convergencia

**Se√±ales de √©xito** (detener si aparecen):
- ‚úÖ Val Accuracy mejora consistentemente (epochs 1-10)
- ‚úÖ Val Loss decrece suavemente
- ‚úÖ Test Accuracy alineado con Val Accuracy (diferencia < 2%)
- ‚úÖ F1-Score > 0.82 (Transfer) o > 0.80 (Small) en √©poca 15-20

**Se√±ales de problemas** (detener inmediatamente):
- ‚ùå Val Accuracy estancada por 3+ √©pocas consecutivas
- ‚ùå Val Accuracy oscila >5% entre √©pocas
- ‚ùå Test Accuracy diverge >5% de Val Accuracy
- ‚ùå VRAM > 7 GB (Transfer) o > 5 GB (Small)

---

## üìà Expectativas Realistas (11 A√±os, Config Corregida)

### Transfer Learning (seq_len=1440, 8L, 1024D)
```
√âpoca    Val Loss    Val Acc    Test Acc    F1-Score (estimado)
-----    --------    --------   ---------   -------------------
  1      0.0355      74-76%     73-75%      0.74-0.76
  5      0.0320      77-79%     76-78%      0.77-0.79
 10      0.0300      79-81%     78-80%      0.79-0.81
 15      0.0285      80-82%     79-81%      0.80-0.82
 20      0.0275      81-83%     80-82%      0.81-0.83 ‚≠ê
 25      0.0270      81-84%     80-83%      0.81-0.84
 30      0.0268      82-84%     81-83%      0.82-0.84 ‚≠ê META
```

**Meta**: F1 > 0.82, Val Acc > 81%, Test Acc > 80%

---

### Small Model Eficiente (seq_len=1440, 5L, 640D)
```
√âpoca    Val Loss    Val Acc    Test Acc    F1-Score (estimado)
-----    --------    --------   ---------   -------------------
  1      0.0370      73-75%     72-74%      0.73-0.75
  5      0.0335      75-77%     74-76%      0.75-0.77
 10      0.0310      77-79%     76-78%      0.77-0.79
 15      0.0295      78-80%     77-79%      0.78-0.80 ‚≠ê
 20      0.0285      79-81%     78-80%      0.79-0.81
 25      0.0280      79-81%     78-80%      0.79-0.81 ‚≠ê META
```

**Meta**: F1 > 0.80, Val Acc > 79%, Test Acc > 78%

---

## üìù Notas Finales

### Checkpoints guardados (13/Oct/2025)
```
‚úÖ classification_peru_rainfall_timerxl_11years_..._0_20251013_044634.pth
   - √âpoca 1: Val Acc 69.05% (estancado con seq_len=2880)
   - NO usar para evaluaci√≥n final

‚úÖ classification_peru_rainfall_small_improved_11years_..._0_20251013_044634.pth
   - √âpoca 1: Val Acc 75.40% (mejor √©poca, overfitting despu√©s)
   - NO usar para evaluaci√≥n final
```

**Ambos checkpoints son de configuraciones fallidas** ‚Üí Re-entrenar con configuraciones corregidas

---

**√öltima Actualizaci√≥n**: 2025-10-13  
**Pr√≥xima Acci√≥n**: Re-entrenar Transfer Learning (seq_len=1440) + Small Eficiente (5L/640D)  
**Meta**: Transfer Learning F1 > 0.82, Small Model F1 > 0.80
