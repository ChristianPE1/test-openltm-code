{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fafb4827",
   "metadata": {},
   "source": [
    "# üåßÔ∏è Timer-XL Peru Rainfall Prediction - Google Colab\n",
    "\n",
    "This notebook demonstrates the complete pipeline for training Timer-XL on Peru rainfall data.\n",
    "\n",
    "**Steps:**\n",
    "1. Setup environment\n",
    "2. Upload ERA5 data\n",
    "3. Preprocess data\n",
    "4. Train Timer-XL with transfer learning\n",
    "5. Evaluate results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb58468",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6436bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660775a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/ChristianPE1/test-openltm-code.git\n",
    "%cd test-openltm-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b831b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92910c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (to download checkpoint.pth and save training results)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"‚úÖ Google Drive mounted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5524612e",
   "metadata": {},
   "source": [
    "## 2. Verificar Datos ERA5\n",
    "\n",
    "**Los archivos .nc ya est√°n en el repositorio** (datasets/raw_era5/)  \n",
    "Solo necesitas verificar que se clonaron correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e662f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify ERA5 files are in the repository\n",
    "!ls -lh datasets/raw_era5/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9543ac7",
   "metadata": {},
   "source": [
    "## 3. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b5ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run preprocessing script\n",
    "!python preprocessing/preprocess_era5_peru.py \\\n",
    "    --input_dir datasets/raw_era5 \\\n",
    "    --output_dir datasets/processed \\\n",
    "    --years 2022,2023,2024 \\\n",
    "    --target_horizon 24 \\\n",
    "    --threshold 0.1\n",
    "\n",
    "print(\"\\n‚úÖ Preprocessing complete!\")\n",
    "print(\"üìä Output files saved to: datasets/processed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa2e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data for quick inspection\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df = pd.read_csv('datasets/processed/peru_rainfall.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Load statistics\n",
    "with open('datasets/processed/preprocessing_stats.json') as f:\n",
    "    stats = json.load(f)\n",
    "print(f\"\\nStatistics:\")\n",
    "print(json.dumps(stats, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18d6979",
   "metadata": {},
   "source": [
    "## 4. Train Timer-XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8babaa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy pre-trained checkpoint from Google Drive\n",
    "import os\n",
    "\n",
    "checkpoint_dir = 'checkpoints/timer_xl'\n",
    "checkpoint_path = f'{checkpoint_dir}/checkpoint.pth'\n",
    "\n",
    "\n",
    "!mkdir -p checkpoints/timer_xl/\n",
    "\n",
    "!cp '/content/drive/MyDrive/timer_xl_peru/checkpoints/checkpoint.pth' \\\n",
    "    checkpoints/timer_xl/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Timer-XL with transfer learning\n",
    "# This will take 4-6 hours on T4 GPU\n",
    "\n",
    "!python run.py \\\n",
    "  --task_name classification \\\n",
    "  --is_training 1 \\\n",
    "  --model_id peru_rainfall_timerxl \\\n",
    "  --model timer_xl_classifier \\\n",
    "  --data PeruRainfall \\\n",
    "  --root_path datasets/processed/ \\\n",
    "  --data_path peru_rainfall.csv \\\n",
    "  --checkpoints checkpoints/ \\\n",
    "  --seq_len 1440 \\\n",
    "  --input_token_len 96 \\\n",
    "  --output_token_len 96 \\\n",
    "  --test_seq_len 1440 \\\n",
    "  --test_pred_len 2 \\\n",
    "  --e_layers 8 \\\n",
    "  --d_model 1024 \\\n",
    "  --d_ff 2048 \\\n",
    "  --n_heads 8 \\\n",
    "  --dropout 0.1 \\\n",
    "  --activation relu \\\n",
    "  --batch_size 128 \\\n",
    "  --learning_rate 1e-5 \\\n",
    "  --train_epochs 50 \\\n",
    "  --patience 10 \\\n",
    "  --n_classes 2 \\\n",
    "  --gpu 0 \\\n",
    "  --cosine \\\n",
    "  --tmax 50 \\\n",
    "  --use_norm \\\n",
    "  --adaptation \\\n",
    "  --pretrain_model_path checkpoints/timer_xl/checkpoint.pth \\\n",
    "  --use_focal_loss \\\n",
    "  --loss CE \\\n",
    "  --itr 1 \\\n",
    "  --des 'Peru_Rainfall_Transfer_Learning'\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")\n",
    "print(\"üìä Results saved to: checkpoints/peru_rainfall_timerxl/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae69d19",
   "metadata": {},
   "source": [
    "## 5. Save Checkpoint to Drive\n",
    "\n",
    "Prevent losing your trained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63515cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy training results to Google Drive (prevent losing trained model!)\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Find the checkpoint directory\n",
    "checkpoint_base = 'checkpoints'\n",
    "results_pattern = f'{checkpoint_base}/*/peru_rainfall_timerxl*/'\n",
    "\n",
    "matching_dirs = glob.glob(results_pattern)\n",
    "\n",
    "if matching_dirs:\n",
    "    results_path = matching_dirs[0]\n",
    "    \n",
    "    # Copy entire results folder to Drive\n",
    "    drive_results = '/content/drive/MyDrive/timer_xl_peru/results/'\n",
    "    os.makedirs(drive_results, exist_ok=True)\n",
    "    \n",
    "    print(\"üíæ Copying results to Google Drive...\")\n",
    "    print(f\"   From: {results_path}\")\n",
    "    print(f\"   To: {drive_results}\")\n",
    "    \n",
    "    # Use shutil for better error handling\n",
    "    try:\n",
    "        shutil.copytree(results_path, os.path.join(drive_results, os.path.basename(results_path.rstrip('/'))), dirs_exist_ok=True)\n",
    "        print(\"‚úÖ Checkpoint and results saved to Google Drive!\")\n",
    "        print(f\"üìÅ Location: {drive_results}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error copying to Drive: {e}\")\n",
    "        print(\"   You can manually copy from:\", results_path)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No results found. Training may have failed or is still in progress.\")\n",
    "    print(\"   Expected pattern:\", results_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a370af7c",
   "metadata": {},
   "source": [
    "## 6. Quick Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4381898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display test results\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# Find results directory\n",
    "checkpoint_base = 'checkpoints'\n",
    "results_pattern = f'{checkpoint_base}/*/peru_rainfall_timerxl*/'\n",
    "matching_dirs = glob.glob(results_pattern)\n",
    "\n",
    "if matching_dirs:\n",
    "    results_dir = matching_dirs[0]\n",
    "    print(f\"üìÇ Results directory: {results_dir}\\n\")\n",
    "    \n",
    "    # List all files\n",
    "    print(\"üìÑ Files in results:\")\n",
    "    for file in os.listdir(results_dir):\n",
    "        print(f\"   - {file}\")\n",
    "    \n",
    "    # Try to load metrics\n",
    "    metrics_files = glob.glob(os.path.join(results_dir, '*metrics*.json'))\n",
    "    \n",
    "    if metrics_files:\n",
    "        print(f\"\\nüìä Loading metrics from: {metrics_files[0]}\")\n",
    "        with open(metrics_files[0]) as f:\n",
    "            metrics = json.load(f)\n",
    "        print(\"\\n‚úÖ Test Metrics:\")\n",
    "        print(json.dumps(metrics, indent=2))\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No metrics file found yet. Training may still be in progress.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No results directory found. Training may have failed.\")\n",
    "    print(f\"   Expected pattern: {results_pattern}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268598ae",
   "metadata": {},
   "source": [
    "## üéâ Training Complete!\n",
    "\n",
    "**Next steps:**\n",
    "1. Download results from `results/peru_rainfall/`\n",
    "2. Analyze confusion matrix and classification report\n",
    "3. Try different context lengths (seq_len)\n",
    "4. Experiment with different hyperparameters"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
