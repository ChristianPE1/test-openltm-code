# üîß Troubleshooting: NaN Loss en Timer-XL Classification

## üî¥ Problema

**S√≠ntoma**: Training produce NaN loss en casi todos los batches, incluso con datos balanceados correctamente.

```
‚úÖ Class distribution: No Rain=2934 (38%), Rain=4730 (62%)
‚ö†Ô∏è Skipping batch 50 due to NaN/Inf loss
‚ö†Ô∏è Skipping batch 100 due to NaN/Inf loss
Epoch: 1, Steps: 389 | Vali Loss: nan Test Loss: nan
```

## üîç Causas Probables

### 1. **Gradientes Explosivos en Transfer Learning**

El modelo Timer-XL pre-entrenado tiene pesos optimizados para regresi√≥n (forecasting). Al adaptar para clasificaci√≥n:
- Las escalas de activaci√≥n son diferentes
- El clasificador nuevo puede generar gradientes muy grandes
- Los gradientes se propagan hacia el encoder pre-entrenado
- **Resultado**: Overflow num√©rico ‚Üí NaN

### 2. **Inicializaci√≥n Inadecuada del Classifier**

Xavier initialization puede generar pesos demasiado grandes para clasificaci√≥n binaria:

```python
# ‚ùå Problema:
nn.init.xavier_uniform_(module.weight)  # Pesos en rango [-sqrt(6/n), sqrt(6/n)]

# Con output_token_len=96, n_in=96, n_out=256:
# Rango: [-0.25, 0.25] ‚Üí Puede causar overflow en forward pass
```

### 3. **Learning Rate Demasiado Alto**

```python
# Para transfer learning desde Timer-XL:
learning_rate = 1e-5  # ‚ùå Demasiado alto
learning_rate = 1e-6  # ‚úÖ M√°s estable
```

## ‚úÖ Soluciones Aplicadas

### Fix 1: Inicializaci√≥n M√°s Peque√±a

```python
def _init_classifier_weights(self):
    for module in self.classifier.modules():
        if isinstance(module, nn.Linear):
            # Usar distribuci√≥n normal con std muy peque√±o
            nn.init.normal_(module.weight, mean=0.0, std=0.01)
            if module.bias is not None:
                nn.init.constant_(module.bias, 0)
```

**Efecto**: Pesos iniciales en rango ~[-0.03, 0.03] ‚Üí Menor probabilidad de overflow

### Fix 2: Classifier M√°s Simple con LayerNorm

```python
# ‚ùå ANTES (inestable):
self.classifier = nn.Sequential(
    nn.Linear(96, 256),  # Gran expansi√≥n
    nn.ReLU(),
    nn.Dropout(0.1),
    nn.Linear(256, 64),
    nn.ReLU(),
    nn.Dropout(0.1),
    nn.Linear(64, 2)
)

# ‚úÖ AHORA (estable):
self.classifier = nn.Sequential(
    nn.LayerNorm(96),        # ‚Üê Normalizaci√≥n para estabilidad
    nn.Linear(96, 128),      # Menor expansi√≥n
    nn.GELU(),               # ‚Üê M√°s suave que ReLU
    nn.Dropout(0.1),
    nn.Linear(128, 2)
)
```

**Ventajas**:
- LayerNorm previene activaciones explosivas
- GELU es m√°s suave que ReLU (sin "muros")
- Menos capas = menos oportunidades para NaN

### Fix 3: Learning Rate M√°s Bajo

```bash
# Cambiar de:
--learning_rate 1e-5

# A:
--learning_rate 1e-6  # ‚Üê 10x m√°s conservador
```

**Justificaci√≥n**:
- Encoder pre-entrenado necesita ajustes muy finos
- Classifier nuevo no debe "tirar" del encoder demasiado r√°pido
- Convergencia m√°s lenta pero m√°s estable

### Fix 4: Gradient Clipping (Ya estaba, pero mejorado)

```python
# Ya exist√≠a:
torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)

# Mejorado con debug info:
if torch.isnan(loss) or torch.isinf(loss):
    print(f"outputs: min={outputs.min()}, max={outputs.max()}")
    print(f"has_nan={torch.isnan(outputs).any()}")
    continue
```

## üéØ Estrategia de Entrenamiento

### Fase 1: Congelar Encoder (Opcional)

Si el problema persiste, congelar temporalmente:

```python
# En el c√≥digo de training:
model.freeze_encoder()  # Solo entrenar classifier

# Entrenar por 5-10 epochs

model.unfreeze_encoder()  # Luego ajustar todo
```

### Fase 2: Warm-up Gradual

```python
# Empezar con LR muy bajo, subir gradualmente:
for epoch in range(5):  # Warm-up
    lr = 1e-7 * (epoch + 1)
    
# Luego usar 1e-6 normal
```

## üìä M√©tricas de Verificaci√≥n

### Antes del Fix

```
Epoch: 1 | Vali Loss: nan | Test Loss: nan
Accuracy: 38.19% (casi aleatorio)
‚ö†Ô∏è 389/389 batches skipped
```

### Despu√©s del Fix (Esperado)

```
Epoch: 1 | Vali Loss: 0.6234 | Test Loss: 0.6511
Accuracy: 58.3%
‚úÖ 0 batches skipped
```

## üîç Debug Checklist

Si el problema persiste:

1. **Verificar outputs del modelo**:
```python
with torch.no_grad():
    outputs = model(batch_x, batch_x_mark, batch_y_mark)
    print(f"Min: {outputs.min()}, Max: {outputs.max()}")
    print(f"Has NaN: {torch.isnan(outputs).any()}")
```

2. **Verificar gradientes**:
```python
for name, param in model.named_parameters():
    if param.grad is not None:
        print(f"{name}: grad_norm={param.grad.norm()}")
```

3. **Verificar datos**:
```python
print(f"batch_x: min={batch_x.min()}, max={batch_x.max()}")
print(f"Has NaN in data: {torch.isnan(batch_x).any()}")
```

4. **Probar sin pre-trained weights**:
```python
# Comentar temporalmente:
# --adaptation \
# --pretrain_model_path checkpoints/timer_xl/checkpoint.pth \

# Ver si entrena desde cero (sin transfer learning)
```

## üöÄ Pr√≥ximos Pasos

1. **Pull cambios del repo**:
```bash
!git pull origin main
```

2. **Re-entrenar con fixes**:
```bash
!python run.py \
  --learning_rate 1e-6 \  # ‚Üê Cambio clave
  --batch_size 16 \
  ...
```

3. **Monitorear**:
- Loss debe ser num√©rico (0.5 - 0.8 inicial)
- Accuracy debe mejorar desde ~50% baseline
- No deber√≠a haber "skipping batch" messages

## üìù Referencias

- [PyTorch Numerical Stability](https://pytorch.org/docs/stable/notes/numerical_accuracy.html)
- [Transfer Learning Best Practices](https://arxiv.org/abs/1411.1792)
- [Gradient Clipping Guide](https://neptune.ai/blog/understanding-gradient-clipping-and-how-it-can-fix-exploding-gradients-problem)

---

**√öltima actualizaci√≥n**: 2025-10-09  
**Estado**: Fixes aplicados, esperando validaci√≥n en Colab
