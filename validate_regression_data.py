"""
Quick validation script for regression data after bug fix
Run this BEFORE training to confirm data is correct

Usage:
    python validate_regression_data.py --data_path datasets/processed/peru_rainfall_regression_cleaned.csv
"""

import argparse
import pandas as pd
import numpy as np
import sys


def validate_regression_data(data_path):
    """Validate that regression data has realistic precipitation values"""
    
    print("="*80)
    print("üîç VALIDACI√ìN DE DATOS DE REGRESI√ìN")
    print("="*80)
    print(f"\nüìÇ Archivo: {data_path}\n")
    
    # Load data
    try:
        df = pd.read_csv(data_path)
        print(f"‚úÖ Datos cargados: {df.shape}")
    except Exception as e:
        print(f"‚ùå ERROR al cargar datos: {e}")
        return False
    
    # Check target column exists
    if 'target_precip_24h' not in df.columns:
        print("‚ùå ERROR: Columna 'target_precip_24h' no encontrada")
        print(f"   Columnas disponibles: {df.columns.tolist()}")
        return False
    
    target = df['target_precip_24h']
    
    # Basic statistics
    print("\nüìä ESTAD√çSTICAS B√ÅSICAS:")
    print(f"   Samples: {len(target)}")
    print(f"   Min: {target.min():.3f} mm")
    print(f"   Max: {target.max():.3f} mm")
    print(f"   Mean: {target.mean():.3f} mm")
    print(f"   Median: {target.median():.3f} mm")
    print(f"   Std: {target.std():.3f} mm")
    print(f"   25%: {target.quantile(0.25):.3f} mm")
    print(f"   75%: {target.quantile(0.75):.3f} mm")
    print(f"   95%: {target.quantile(0.95):.3f} mm")
    print(f"   99%: {target.quantile(0.99):.3f} mm")
    
    # Rainfall distribution
    rainy_pct = 100 * (target > 0.1).sum() / len(target)
    heavy_pct = 100 * (target > 10.0).sum() / len(target)
    extreme_pct = 100 * (target > 50.0).sum() / len(target)
    
    print("\nüìä DISTRIBUCI√ìN DE LLUVIA:")
    print(f"   Rainy (>0.1mm): {rainy_pct:.1f}%")
    print(f"   Heavy (>10mm): {heavy_pct:.2f}%")
    print(f"   Extreme (>50mm): {extreme_pct:.2f}%")
    
    # Check for NaN
    nan_count = target.isna().sum()
    print(f"\nüîç VALORES FALTANTES:")
    print(f"   NaN count: {nan_count} ({100*nan_count/len(target):.2f}%)")
    
    # VALIDATION CHECKS
    print("\n" + "="*80)
    print("‚úÖ VERIFICACI√ìN DE CORRECCIONES")
    print("="*80)
    
    all_passed = True
    
    # CHECK 1: Max value should be realistic (>20mm)
    print("\n[1/6] Verificando valor m√°ximo...")
    if target.max() > 20:
        print(f"   ‚úÖ PASS: Max = {target.max():.1f} mm (realista)")
    else:
        print(f"   ‚ùå FAIL: Max = {target.max():.1f} mm (muy bajo, bug no corregido)")
        print(f"        Esperado: >20mm (eventos de lluvia intensa)")
        all_passed = False
    
    # CHECK 2: Mean should be reasonable (1-10mm)
    print("\n[2/6] Verificando valor medio...")
    if 1.0 < target.mean() < 15.0:
        print(f"   ‚úÖ PASS: Mean = {target.mean():.1f} mm (realista)")
    else:
        print(f"   ‚ö†Ô∏è  WARNING: Mean = {target.mean():.1f} mm")
        if target.mean() < 1.0:
            print(f"        Muy bajo - posible bug en acumulaci√≥n")
            all_passed = False
        else:
            print(f"        Alto pero posible para regi√≥n con mucha lluvia")
    
    # CHECK 3: Should have heavy rain events (>10mm)
    print("\n[3/6] Verificando eventos de lluvia intensa...")
    if heavy_pct > 1.0:
        print(f"   ‚úÖ PASS: Heavy rain = {heavy_pct:.2f}% (eventos capturados)")
    else:
        print(f"   ‚ùå FAIL: Heavy rain = {heavy_pct:.2f}% (muy bajo)")
        print(f"        Costa de Per√∫ tiene eventos ENSO con >10mm")
        all_passed = False
    
    # CHECK 4: Should have some extreme events (>50mm) for El Ni√±o
    print("\n[4/6] Verificando eventos extremos ENSO...")
    if extreme_pct > 0.1:
        print(f"   ‚úÖ PASS: Extreme rain = {extreme_pct:.2f}% (eventos ENSO capturados)")
    elif extreme_pct > 0:
        print(f"   ‚ö†Ô∏è  WARNING: Extreme rain = {extreme_pct:.2f}% (bajo pero presente)")
    else:
        print(f"   ‚ö†Ô∏è  WARNING: Extreme rain = 0% (sin eventos >50mm)")
        print(f"        Puede ser normal si datos no incluyen El Ni√±o fuerte")
    
    # CHECK 5: No NaN values
    print("\n[5/6] Verificando valores faltantes...")
    if nan_count == 0:
        print(f"   ‚úÖ PASS: No NaN values")
    else:
        print(f"   ‚ùå FAIL: {nan_count} NaN values ({100*nan_count/len(target):.2f}%)")
        print(f"        Ejecutar clean_regression_data.py")
        all_passed = False
    
    # CHECK 6: Data is continuous (not binary)
    print("\n[6/6] Verificando que datos son continuos...")
    unique_values = target.nunique()
    if unique_values > 100:
        print(f"   ‚úÖ PASS: {unique_values} valores √∫nicos (datos continuos)")
    else:
        print(f"   ‚ùå FAIL: {unique_values} valores √∫nicos (datos binarios/categ√≥ricos)")
        print(f"        Datos de regresi√≥n deben tener muchos valores √∫nicos")
        all_passed = False
    
    # FINAL VERDICT
    print("\n" + "="*80)
    if all_passed:
        print("üéâ ¬°VALIDACI√ìN EXITOSA!")
        print("="*80)
        print("\n‚úÖ Los datos est√°n correctos y listos para entrenamiento")
        print("\nüìä M√âTRICAS ESPERADAS:")
        print("   ‚Ä¢ RMSE: 2-5 mm (NASA IMERG: 3.4mm)")
        print("   ‚Ä¢ MAE: 1.5-3.5 mm")
        print("   ‚Ä¢ R¬≤: 0.40-0.70")
        print("\nüí° PR√ìXIMO PASO:")
        print("   Ejecutar celda 'Entrenamiento Regresi√≥n' en el notebook")
        print("="*80)
        return True
    else:
        print("‚ùå VALIDACI√ìN FALLIDA")
        print("="*80)
        print("\n‚ö†Ô∏è  Los datos tienen problemas. Posibles causas:")
        print("   1. Bug en preprocess_era5_regression.py no corregido")
        print("   2. Datos de entrada (ERA5 .nc) corruptos")
        print("   3. Limpieza de datos (clean_regression_data.py) no ejecutada")
        print("\nüîß SOLUCI√ìN:")
        print("   1. Verificar que archivos .py tienen correcciones (ver CORRECCION_REGRESION_2025_01_18.md)")
        print("   2. Re-ejecutar preprocessing:")
        print("      !python preprocessing/preprocess_era5_regression.py ...")
        print("   3. Re-ejecutar limpieza:")
        print("      !python preprocessing/clean_regression_data.py ...")
        print("   4. Re-ejecutar este script de validaci√≥n")
        print("="*80)
        return False


def main():
    parser = argparse.ArgumentParser(description='Validate regression data after bug fix')
    parser.add_argument('--data_path', type=str, 
                        default='datasets/processed/peru_rainfall_regression_cleaned.csv',
                        help='Path to cleaned regression CSV')
    
    args = parser.parse_args()
    
    success = validate_regression_data(args.data_path)
    
    # Exit code (for automation)
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()
